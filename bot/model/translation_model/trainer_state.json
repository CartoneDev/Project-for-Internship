{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 5148,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005829204313611192,
      "grad_norm": 20.500486373901367,
      "learning_rate": 8.000000000000001e-06,
      "loss": 6.0037,
      "step": 10
    },
    {
      "epoch": 0.011658408627222384,
      "grad_norm": 9.29057788848877,
      "learning_rate": 1.8e-05,
      "loss": 4.1123,
      "step": 20
    },
    {
      "epoch": 0.017487612940833577,
      "grad_norm": 3.401890277862549,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 2.7602,
      "step": 30
    },
    {
      "epoch": 0.023316817254444767,
      "grad_norm": 1.333743691444397,
      "learning_rate": 3.8e-05,
      "loss": 2.06,
      "step": 40
    },
    {
      "epoch": 0.02914602156805596,
      "grad_norm": 0.8221899271011353,
      "learning_rate": 4.8e-05,
      "loss": 1.6507,
      "step": 50
    },
    {
      "epoch": 0.034975225881667155,
      "grad_norm": 0.7871352434158325,
      "learning_rate": 4.9921537857983526e-05,
      "loss": 1.3778,
      "step": 60
    },
    {
      "epoch": 0.040804430195278345,
      "grad_norm": 0.6053329110145569,
      "learning_rate": 4.982346018046293e-05,
      "loss": 1.2065,
      "step": 70
    },
    {
      "epoch": 0.046633634508889535,
      "grad_norm": 0.5247015953063965,
      "learning_rate": 4.9725382502942334e-05,
      "loss": 1.0868,
      "step": 80
    },
    {
      "epoch": 0.05246283882250073,
      "grad_norm": 0.5245456099510193,
      "learning_rate": 4.962730482542174e-05,
      "loss": 1.0058,
      "step": 90
    },
    {
      "epoch": 0.05829204313611192,
      "grad_norm": 0.6479369401931763,
      "learning_rate": 4.952922714790114e-05,
      "loss": 0.9478,
      "step": 100
    },
    {
      "epoch": 0.05829204313611192,
      "eval_loss": 0.7289305925369263,
      "eval_runtime": 92.3863,
      "eval_samples_per_second": 374.677,
      "eval_steps_per_second": 46.836,
      "step": 100
    },
    {
      "epoch": 0.06412124744972311,
      "grad_norm": 0.557678759098053,
      "learning_rate": 4.9431149470380546e-05,
      "loss": 0.8892,
      "step": 110
    },
    {
      "epoch": 0.06995045176333431,
      "grad_norm": 0.5603440999984741,
      "learning_rate": 4.933307179285995e-05,
      "loss": 0.8462,
      "step": 120
    },
    {
      "epoch": 0.07577965607694549,
      "grad_norm": 0.5185230374336243,
      "learning_rate": 4.923499411533935e-05,
      "loss": 0.8037,
      "step": 130
    },
    {
      "epoch": 0.08160886039055669,
      "grad_norm": 0.4737410247325897,
      "learning_rate": 4.913691643781875e-05,
      "loss": 0.77,
      "step": 140
    },
    {
      "epoch": 0.08743806470416789,
      "grad_norm": 0.4761602580547333,
      "learning_rate": 4.9038838760298155e-05,
      "loss": 0.7466,
      "step": 150
    },
    {
      "epoch": 0.09326726901777907,
      "grad_norm": 0.5183850526809692,
      "learning_rate": 4.8940761082777566e-05,
      "loss": 0.7185,
      "step": 160
    },
    {
      "epoch": 0.09909647333139027,
      "grad_norm": 0.5546748042106628,
      "learning_rate": 4.884268340525697e-05,
      "loss": 0.6953,
      "step": 170
    },
    {
      "epoch": 0.10492567764500146,
      "grad_norm": 0.5748003721237183,
      "learning_rate": 4.874460572773637e-05,
      "loss": 0.6722,
      "step": 180
    },
    {
      "epoch": 0.11075488195861265,
      "grad_norm": 0.44474899768829346,
      "learning_rate": 4.864652805021577e-05,
      "loss": 0.6553,
      "step": 190
    },
    {
      "epoch": 0.11658408627222384,
      "grad_norm": 0.6591724157333374,
      "learning_rate": 4.8548450372695175e-05,
      "loss": 0.6351,
      "step": 200
    },
    {
      "epoch": 0.11658408627222384,
      "eval_loss": 0.47146645188331604,
      "eval_runtime": 91.2149,
      "eval_samples_per_second": 379.488,
      "eval_steps_per_second": 47.437,
      "step": 200
    },
    {
      "epoch": 0.12241329058583503,
      "grad_norm": 0.6453573107719421,
      "learning_rate": 4.845037269517458e-05,
      "loss": 0.6119,
      "step": 210
    },
    {
      "epoch": 0.12824249489944622,
      "grad_norm": 0.46612608432769775,
      "learning_rate": 4.8352295017653984e-05,
      "loss": 0.5998,
      "step": 220
    },
    {
      "epoch": 0.13407169921305742,
      "grad_norm": 0.6246639490127563,
      "learning_rate": 4.825421734013339e-05,
      "loss": 0.584,
      "step": 230
    },
    {
      "epoch": 0.13990090352666862,
      "grad_norm": 0.42770302295684814,
      "learning_rate": 4.815613966261279e-05,
      "loss": 0.5706,
      "step": 240
    },
    {
      "epoch": 0.14573010784027982,
      "grad_norm": 0.40180251002311707,
      "learning_rate": 4.8058061985092196e-05,
      "loss": 0.5554,
      "step": 250
    },
    {
      "epoch": 0.15155931215389098,
      "grad_norm": 0.3910601735115051,
      "learning_rate": 4.79599843075716e-05,
      "loss": 0.5431,
      "step": 260
    },
    {
      "epoch": 0.15738851646750218,
      "grad_norm": 0.4242709279060364,
      "learning_rate": 4.7861906630051004e-05,
      "loss": 0.5256,
      "step": 270
    },
    {
      "epoch": 0.16321772078111338,
      "grad_norm": 0.48961320519447327,
      "learning_rate": 4.77638289525304e-05,
      "loss": 0.5249,
      "step": 280
    },
    {
      "epoch": 0.16904692509472458,
      "grad_norm": 0.4172525703907013,
      "learning_rate": 4.766575127500981e-05,
      "loss": 0.5132,
      "step": 290
    },
    {
      "epoch": 0.17487612940833577,
      "grad_norm": 0.397517591714859,
      "learning_rate": 4.7567673597489216e-05,
      "loss": 0.5005,
      "step": 300
    },
    {
      "epoch": 0.17487612940833577,
      "eval_loss": 0.3563019931316376,
      "eval_runtime": 92.4587,
      "eval_samples_per_second": 374.383,
      "eval_steps_per_second": 46.799,
      "step": 300
    },
    {
      "epoch": 0.18070533372194694,
      "grad_norm": 0.377941757440567,
      "learning_rate": 4.746959591996862e-05,
      "loss": 0.4912,
      "step": 310
    },
    {
      "epoch": 0.18653453803555814,
      "grad_norm": 0.40275514125823975,
      "learning_rate": 4.7371518242448024e-05,
      "loss": 0.4808,
      "step": 320
    },
    {
      "epoch": 0.19236374234916934,
      "grad_norm": 0.37405750155448914,
      "learning_rate": 4.727344056492742e-05,
      "loss": 0.4792,
      "step": 330
    },
    {
      "epoch": 0.19819294666278053,
      "grad_norm": 0.4083901047706604,
      "learning_rate": 4.7175362887406825e-05,
      "loss": 0.4698,
      "step": 340
    },
    {
      "epoch": 0.20402215097639173,
      "grad_norm": 0.4375077188014984,
      "learning_rate": 4.7077285209886236e-05,
      "loss": 0.468,
      "step": 350
    },
    {
      "epoch": 0.20985135529000293,
      "grad_norm": 0.39833804965019226,
      "learning_rate": 4.697920753236564e-05,
      "loss": 0.461,
      "step": 360
    },
    {
      "epoch": 0.2156805596036141,
      "grad_norm": 0.39271312952041626,
      "learning_rate": 4.688112985484504e-05,
      "loss": 0.4475,
      "step": 370
    },
    {
      "epoch": 0.2215097639172253,
      "grad_norm": 0.3990802764892578,
      "learning_rate": 4.678305217732444e-05,
      "loss": 0.4417,
      "step": 380
    },
    {
      "epoch": 0.2273389682308365,
      "grad_norm": 0.43555474281311035,
      "learning_rate": 4.6684974499803845e-05,
      "loss": 0.434,
      "step": 390
    },
    {
      "epoch": 0.2331681725444477,
      "grad_norm": 0.41169264912605286,
      "learning_rate": 4.658689682228325e-05,
      "loss": 0.4288,
      "step": 400
    },
    {
      "epoch": 0.2331681725444477,
      "eval_loss": 0.3014627993106842,
      "eval_runtime": 92.5678,
      "eval_samples_per_second": 373.942,
      "eval_steps_per_second": 46.744,
      "step": 400
    },
    {
      "epoch": 0.23899737685805889,
      "grad_norm": 0.47679585218429565,
      "learning_rate": 4.6488819144762654e-05,
      "loss": 0.4251,
      "step": 410
    },
    {
      "epoch": 0.24482658117167005,
      "grad_norm": 0.41645267605781555,
      "learning_rate": 4.639074146724206e-05,
      "loss": 0.4207,
      "step": 420
    },
    {
      "epoch": 0.2506557854852813,
      "grad_norm": 0.3672598600387573,
      "learning_rate": 4.629266378972146e-05,
      "loss": 0.4147,
      "step": 430
    },
    {
      "epoch": 0.25648498979889245,
      "grad_norm": 0.4074569046497345,
      "learning_rate": 4.6194586112200866e-05,
      "loss": 0.4088,
      "step": 440
    },
    {
      "epoch": 0.2623141941125036,
      "grad_norm": 0.42053258419036865,
      "learning_rate": 4.609650843468027e-05,
      "loss": 0.402,
      "step": 450
    },
    {
      "epoch": 0.26814339842611484,
      "grad_norm": 0.38586270809173584,
      "learning_rate": 4.5998430757159674e-05,
      "loss": 0.3967,
      "step": 460
    },
    {
      "epoch": 0.273972602739726,
      "grad_norm": 0.41264715790748596,
      "learning_rate": 4.590035307963908e-05,
      "loss": 0.3964,
      "step": 470
    },
    {
      "epoch": 0.27980180705333724,
      "grad_norm": 0.40823307633399963,
      "learning_rate": 4.5802275402118475e-05,
      "loss": 0.3903,
      "step": 480
    },
    {
      "epoch": 0.2856310113669484,
      "grad_norm": 0.3693705201148987,
      "learning_rate": 4.5704197724597886e-05,
      "loss": 0.3861,
      "step": 490
    },
    {
      "epoch": 0.29146021568055963,
      "grad_norm": 0.3692544400691986,
      "learning_rate": 4.560612004707729e-05,
      "loss": 0.382,
      "step": 500
    },
    {
      "epoch": 0.29146021568055963,
      "eval_loss": 0.26446616649627686,
      "eval_runtime": 92.0818,
      "eval_samples_per_second": 375.916,
      "eval_steps_per_second": 46.991,
      "step": 500
    },
    {
      "epoch": 0.2972894199941708,
      "grad_norm": 0.377847820520401,
      "learning_rate": 4.5508042369556694e-05,
      "loss": 0.376,
      "step": 510
    },
    {
      "epoch": 0.30311862430778197,
      "grad_norm": 0.3620723485946655,
      "learning_rate": 4.540996469203609e-05,
      "loss": 0.3779,
      "step": 520
    },
    {
      "epoch": 0.3089478286213932,
      "grad_norm": 0.3430025577545166,
      "learning_rate": 4.5311887014515495e-05,
      "loss": 0.375,
      "step": 530
    },
    {
      "epoch": 0.31477703293500436,
      "grad_norm": 0.3779078722000122,
      "learning_rate": 4.52138093369949e-05,
      "loss": 0.3704,
      "step": 540
    },
    {
      "epoch": 0.3206062372486156,
      "grad_norm": 0.36371076107025146,
      "learning_rate": 4.511573165947431e-05,
      "loss": 0.3624,
      "step": 550
    },
    {
      "epoch": 0.32643544156222676,
      "grad_norm": 0.33582618832588196,
      "learning_rate": 4.5017653981953714e-05,
      "loss": 0.3632,
      "step": 560
    },
    {
      "epoch": 0.3322646458758379,
      "grad_norm": 0.34042659401893616,
      "learning_rate": 4.491957630443311e-05,
      "loss": 0.3565,
      "step": 570
    },
    {
      "epoch": 0.33809385018944915,
      "grad_norm": 0.32997432351112366,
      "learning_rate": 4.4821498626912515e-05,
      "loss": 0.3529,
      "step": 580
    },
    {
      "epoch": 0.3439230545030603,
      "grad_norm": 0.3485860526561737,
      "learning_rate": 4.472342094939192e-05,
      "loss": 0.3537,
      "step": 590
    },
    {
      "epoch": 0.34975225881667155,
      "grad_norm": 0.3436893820762634,
      "learning_rate": 4.4625343271871324e-05,
      "loss": 0.3487,
      "step": 600
    },
    {
      "epoch": 0.34975225881667155,
      "eval_loss": 0.23799963295459747,
      "eval_runtime": 92.2113,
      "eval_samples_per_second": 375.388,
      "eval_steps_per_second": 46.925,
      "step": 600
    },
    {
      "epoch": 0.3555814631302827,
      "grad_norm": 0.3696475327014923,
      "learning_rate": 4.452726559435073e-05,
      "loss": 0.3467,
      "step": 610
    },
    {
      "epoch": 0.3614106674438939,
      "grad_norm": 0.36205512285232544,
      "learning_rate": 4.442918791683013e-05,
      "loss": 0.3436,
      "step": 620
    },
    {
      "epoch": 0.3672398717575051,
      "grad_norm": 0.3727000057697296,
      "learning_rate": 4.4331110239309536e-05,
      "loss": 0.3411,
      "step": 630
    },
    {
      "epoch": 0.3730690760711163,
      "grad_norm": 0.34892895817756653,
      "learning_rate": 4.423303256178894e-05,
      "loss": 0.3358,
      "step": 640
    },
    {
      "epoch": 0.3788982803847275,
      "grad_norm": 0.36457639932632446,
      "learning_rate": 4.4134954884268344e-05,
      "loss": 0.3367,
      "step": 650
    },
    {
      "epoch": 0.3847274846983387,
      "grad_norm": 0.3793147802352905,
      "learning_rate": 4.403687720674775e-05,
      "loss": 0.3362,
      "step": 660
    },
    {
      "epoch": 0.39055668901194984,
      "grad_norm": 0.34590432047843933,
      "learning_rate": 4.3938799529227145e-05,
      "loss": 0.3262,
      "step": 670
    },
    {
      "epoch": 0.39638589332556107,
      "grad_norm": 0.36120590567588806,
      "learning_rate": 4.384072185170655e-05,
      "loss": 0.3261,
      "step": 680
    },
    {
      "epoch": 0.40221509763917224,
      "grad_norm": 0.354467511177063,
      "learning_rate": 4.374264417418596e-05,
      "loss": 0.3212,
      "step": 690
    },
    {
      "epoch": 0.40804430195278346,
      "grad_norm": 0.34410881996154785,
      "learning_rate": 4.3644566496665364e-05,
      "loss": 0.3251,
      "step": 700
    },
    {
      "epoch": 0.40804430195278346,
      "eval_loss": 0.21727947890758514,
      "eval_runtime": 92.2569,
      "eval_samples_per_second": 375.202,
      "eval_steps_per_second": 46.902,
      "step": 700
    },
    {
      "epoch": 0.41387350626639463,
      "grad_norm": 0.3430996835231781,
      "learning_rate": 4.354648881914477e-05,
      "loss": 0.3187,
      "step": 710
    },
    {
      "epoch": 0.41970271058000586,
      "grad_norm": 0.3622564375400543,
      "learning_rate": 4.3448411141624165e-05,
      "loss": 0.3144,
      "step": 720
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 0.3194740414619446,
      "learning_rate": 4.335033346410357e-05,
      "loss": 0.3163,
      "step": 730
    },
    {
      "epoch": 0.4313611192072282,
      "grad_norm": 0.3379080891609192,
      "learning_rate": 4.325225578658297e-05,
      "loss": 0.3142,
      "step": 740
    },
    {
      "epoch": 0.4371903235208394,
      "grad_norm": 0.3307511508464813,
      "learning_rate": 4.3154178109062384e-05,
      "loss": 0.3056,
      "step": 750
    },
    {
      "epoch": 0.4430195278344506,
      "grad_norm": 0.4013337790966034,
      "learning_rate": 4.305610043154179e-05,
      "loss": 0.3077,
      "step": 760
    },
    {
      "epoch": 0.4488487321480618,
      "grad_norm": 0.3765115439891815,
      "learning_rate": 4.2958022754021185e-05,
      "loss": 0.3059,
      "step": 770
    },
    {
      "epoch": 0.454677936461673,
      "grad_norm": 0.37160125374794006,
      "learning_rate": 4.285994507650059e-05,
      "loss": 0.3032,
      "step": 780
    },
    {
      "epoch": 0.46050714077528415,
      "grad_norm": 0.3264147639274597,
      "learning_rate": 4.2761867398979994e-05,
      "loss": 0.3021,
      "step": 790
    },
    {
      "epoch": 0.4663363450888954,
      "grad_norm": 0.3418462872505188,
      "learning_rate": 4.26637897214594e-05,
      "loss": 0.2994,
      "step": 800
    },
    {
      "epoch": 0.4663363450888954,
      "eval_loss": 0.2013247311115265,
      "eval_runtime": 92.4766,
      "eval_samples_per_second": 374.311,
      "eval_steps_per_second": 46.79,
      "step": 800
    },
    {
      "epoch": 0.47216554940250655,
      "grad_norm": 0.32407230138778687,
      "learning_rate": 4.25657120439388e-05,
      "loss": 0.2947,
      "step": 810
    },
    {
      "epoch": 0.47799475371611777,
      "grad_norm": 0.32632485032081604,
      "learning_rate": 4.2467634366418206e-05,
      "loss": 0.2994,
      "step": 820
    },
    {
      "epoch": 0.48382395802972894,
      "grad_norm": 0.34886252880096436,
      "learning_rate": 4.236955668889761e-05,
      "loss": 0.2946,
      "step": 830
    },
    {
      "epoch": 0.4896531623433401,
      "grad_norm": 0.32312047481536865,
      "learning_rate": 4.2271479011377014e-05,
      "loss": 0.2903,
      "step": 840
    },
    {
      "epoch": 0.49548236665695133,
      "grad_norm": 0.32715851068496704,
      "learning_rate": 4.217340133385642e-05,
      "loss": 0.2878,
      "step": 850
    },
    {
      "epoch": 0.5013115709705626,
      "grad_norm": 0.3448173701763153,
      "learning_rate": 4.207532365633582e-05,
      "loss": 0.292,
      "step": 860
    },
    {
      "epoch": 0.5071407752841737,
      "grad_norm": 0.34495028853416443,
      "learning_rate": 4.197724597881522e-05,
      "loss": 0.2899,
      "step": 870
    },
    {
      "epoch": 0.5129699795977849,
      "grad_norm": 0.3639340400695801,
      "learning_rate": 4.187916830129463e-05,
      "loss": 0.283,
      "step": 880
    },
    {
      "epoch": 0.5187991839113961,
      "grad_norm": 0.32184186577796936,
      "learning_rate": 4.1781090623774034e-05,
      "loss": 0.2876,
      "step": 890
    },
    {
      "epoch": 0.5246283882250072,
      "grad_norm": 0.36048728227615356,
      "learning_rate": 4.168301294625344e-05,
      "loss": 0.2859,
      "step": 900
    },
    {
      "epoch": 0.5246283882250072,
      "eval_loss": 0.18768636882305145,
      "eval_runtime": 92.8831,
      "eval_samples_per_second": 372.673,
      "eval_steps_per_second": 46.585,
      "step": 900
    },
    {
      "epoch": 0.5304575925386185,
      "grad_norm": 0.32127854228019714,
      "learning_rate": 4.1584935268732835e-05,
      "loss": 0.2785,
      "step": 910
    },
    {
      "epoch": 0.5362867968522297,
      "grad_norm": 0.3258805274963379,
      "learning_rate": 4.148685759121224e-05,
      "loss": 0.2833,
      "step": 920
    },
    {
      "epoch": 0.5421160011658409,
      "grad_norm": 0.3277137875556946,
      "learning_rate": 4.1388779913691643e-05,
      "loss": 0.279,
      "step": 930
    },
    {
      "epoch": 0.547945205479452,
      "grad_norm": 0.32867005467414856,
      "learning_rate": 4.129070223617105e-05,
      "loss": 0.2762,
      "step": 940
    },
    {
      "epoch": 0.5537744097930632,
      "grad_norm": 0.3323967754840851,
      "learning_rate": 4.119262455865046e-05,
      "loss": 0.2732,
      "step": 950
    },
    {
      "epoch": 0.5596036141066745,
      "grad_norm": 0.30152013897895813,
      "learning_rate": 4.1094546881129856e-05,
      "loss": 0.2741,
      "step": 960
    },
    {
      "epoch": 0.5654328184202856,
      "grad_norm": 0.30938825011253357,
      "learning_rate": 4.099646920360926e-05,
      "loss": 0.2723,
      "step": 970
    },
    {
      "epoch": 0.5712620227338968,
      "grad_norm": 0.35278651118278503,
      "learning_rate": 4.0898391526088664e-05,
      "loss": 0.2711,
      "step": 980
    },
    {
      "epoch": 0.577091227047508,
      "grad_norm": 0.31545722484588623,
      "learning_rate": 4.080031384856807e-05,
      "loss": 0.2711,
      "step": 990
    },
    {
      "epoch": 0.5829204313611193,
      "grad_norm": 0.3231087327003479,
      "learning_rate": 4.070223617104747e-05,
      "loss": 0.2701,
      "step": 1000
    },
    {
      "epoch": 0.5829204313611193,
      "eval_loss": 0.17650671303272247,
      "eval_runtime": 93.0065,
      "eval_samples_per_second": 372.178,
      "eval_steps_per_second": 46.524,
      "step": 1000
    },
    {
      "epoch": 0.5887496356747304,
      "grad_norm": 0.3199652135372162,
      "learning_rate": 4.0604158493526876e-05,
      "loss": 0.2626,
      "step": 1010
    },
    {
      "epoch": 0.5945788399883416,
      "grad_norm": 0.32207855582237244,
      "learning_rate": 4.050608081600628e-05,
      "loss": 0.2614,
      "step": 1020
    },
    {
      "epoch": 0.6004080443019528,
      "grad_norm": 0.3266462981700897,
      "learning_rate": 4.0408003138485684e-05,
      "loss": 0.2657,
      "step": 1030
    },
    {
      "epoch": 0.6062372486155639,
      "grad_norm": 0.3133275508880615,
      "learning_rate": 4.030992546096509e-05,
      "loss": 0.2657,
      "step": 1040
    },
    {
      "epoch": 0.6120664529291752,
      "grad_norm": 0.30603495240211487,
      "learning_rate": 4.021184778344449e-05,
      "loss": 0.2596,
      "step": 1050
    },
    {
      "epoch": 0.6178956572427864,
      "grad_norm": 0.3084460496902466,
      "learning_rate": 4.011377010592389e-05,
      "loss": 0.26,
      "step": 1060
    },
    {
      "epoch": 0.6237248615563975,
      "grad_norm": 0.327102392911911,
      "learning_rate": 4.001569242840329e-05,
      "loss": 0.2568,
      "step": 1070
    },
    {
      "epoch": 0.6295540658700087,
      "grad_norm": 0.33231598138809204,
      "learning_rate": 3.9917614750882704e-05,
      "loss": 0.2615,
      "step": 1080
    },
    {
      "epoch": 0.63538327018362,
      "grad_norm": 0.3162272870540619,
      "learning_rate": 3.981953707336211e-05,
      "loss": 0.2594,
      "step": 1090
    },
    {
      "epoch": 0.6412124744972312,
      "grad_norm": 0.31529706716537476,
      "learning_rate": 3.972145939584151e-05,
      "loss": 0.2524,
      "step": 1100
    },
    {
      "epoch": 0.6412124744972312,
      "eval_loss": 0.16781511902809143,
      "eval_runtime": 92.9634,
      "eval_samples_per_second": 372.351,
      "eval_steps_per_second": 46.545,
      "step": 1100
    },
    {
      "epoch": 0.6470416788108423,
      "grad_norm": 0.3150240480899811,
      "learning_rate": 3.962338171832091e-05,
      "loss": 0.2527,
      "step": 1110
    },
    {
      "epoch": 0.6528708831244535,
      "grad_norm": 0.3182380497455597,
      "learning_rate": 3.9525304040800313e-05,
      "loss": 0.2538,
      "step": 1120
    },
    {
      "epoch": 0.6587000874380647,
      "grad_norm": 0.3117483854293823,
      "learning_rate": 3.942722636327972e-05,
      "loss": 0.2483,
      "step": 1130
    },
    {
      "epoch": 0.6645292917516759,
      "grad_norm": 0.3047666549682617,
      "learning_rate": 3.932914868575912e-05,
      "loss": 0.2527,
      "step": 1140
    },
    {
      "epoch": 0.6703584960652871,
      "grad_norm": 0.3073636591434479,
      "learning_rate": 3.923107100823853e-05,
      "loss": 0.2545,
      "step": 1150
    },
    {
      "epoch": 0.6761877003788983,
      "grad_norm": 0.31813323497772217,
      "learning_rate": 3.913299333071793e-05,
      "loss": 0.2477,
      "step": 1160
    },
    {
      "epoch": 0.6820169046925094,
      "grad_norm": 0.32287004590034485,
      "learning_rate": 3.9034915653197334e-05,
      "loss": 0.2478,
      "step": 1170
    },
    {
      "epoch": 0.6878461090061206,
      "grad_norm": 0.2919633090496063,
      "learning_rate": 3.893683797567674e-05,
      "loss": 0.2464,
      "step": 1180
    },
    {
      "epoch": 0.6936753133197319,
      "grad_norm": 0.3269675374031067,
      "learning_rate": 3.883876029815614e-05,
      "loss": 0.2445,
      "step": 1190
    },
    {
      "epoch": 0.6995045176333431,
      "grad_norm": 0.30700787901878357,
      "learning_rate": 3.8740682620635546e-05,
      "loss": 0.2438,
      "step": 1200
    },
    {
      "epoch": 0.6995045176333431,
      "eval_loss": 0.15922963619232178,
      "eval_runtime": 92.3712,
      "eval_samples_per_second": 374.738,
      "eval_steps_per_second": 46.844,
      "step": 1200
    },
    {
      "epoch": 0.7053337219469542,
      "grad_norm": 0.30693185329437256,
      "learning_rate": 3.864260494311494e-05,
      "loss": 0.2422,
      "step": 1210
    },
    {
      "epoch": 0.7111629262605654,
      "grad_norm": 0.30887940526008606,
      "learning_rate": 3.8544527265594354e-05,
      "loss": 0.2436,
      "step": 1220
    },
    {
      "epoch": 0.7169921305741767,
      "grad_norm": 0.325723797082901,
      "learning_rate": 3.844644958807376e-05,
      "loss": 0.2394,
      "step": 1230
    },
    {
      "epoch": 0.7228213348877878,
      "grad_norm": 0.30126380920410156,
      "learning_rate": 3.834837191055316e-05,
      "loss": 0.2398,
      "step": 1240
    },
    {
      "epoch": 0.728650539201399,
      "grad_norm": 0.35572877526283264,
      "learning_rate": 3.8250294233032566e-05,
      "loss": 0.2403,
      "step": 1250
    },
    {
      "epoch": 0.7344797435150102,
      "grad_norm": 0.3104005753993988,
      "learning_rate": 3.815221655551196e-05,
      "loss": 0.2384,
      "step": 1260
    },
    {
      "epoch": 0.7403089478286214,
      "grad_norm": 0.3251035809516907,
      "learning_rate": 3.805413887799137e-05,
      "loss": 0.239,
      "step": 1270
    },
    {
      "epoch": 0.7461381521422326,
      "grad_norm": 0.3196007013320923,
      "learning_rate": 3.795606120047078e-05,
      "loss": 0.2344,
      "step": 1280
    },
    {
      "epoch": 0.7519673564558438,
      "grad_norm": 0.30442535877227783,
      "learning_rate": 3.785798352295018e-05,
      "loss": 0.2353,
      "step": 1290
    },
    {
      "epoch": 0.757796560769455,
      "grad_norm": 0.30103248357772827,
      "learning_rate": 3.7759905845429586e-05,
      "loss": 0.2368,
      "step": 1300
    },
    {
      "epoch": 0.757796560769455,
      "eval_loss": 0.1516425609588623,
      "eval_runtime": 92.9369,
      "eval_samples_per_second": 372.457,
      "eval_steps_per_second": 46.558,
      "step": 1300
    },
    {
      "epoch": 0.7636257650830661,
      "grad_norm": 0.30033907294273376,
      "learning_rate": 3.7661828167908983e-05,
      "loss": 0.2331,
      "step": 1310
    },
    {
      "epoch": 0.7694549693966773,
      "grad_norm": 0.2849333882331848,
      "learning_rate": 3.756375049038839e-05,
      "loss": 0.2306,
      "step": 1320
    },
    {
      "epoch": 0.7752841737102886,
      "grad_norm": 0.3392711281776428,
      "learning_rate": 3.746567281286779e-05,
      "loss": 0.2309,
      "step": 1330
    },
    {
      "epoch": 0.7811133780238997,
      "grad_norm": 0.301094114780426,
      "learning_rate": 3.7367595135347196e-05,
      "loss": 0.2344,
      "step": 1340
    },
    {
      "epoch": 0.7869425823375109,
      "grad_norm": 0.30168449878692627,
      "learning_rate": 3.72695174578266e-05,
      "loss": 0.2283,
      "step": 1350
    },
    {
      "epoch": 0.7927717866511221,
      "grad_norm": 0.31009796261787415,
      "learning_rate": 3.7171439780306004e-05,
      "loss": 0.2345,
      "step": 1360
    },
    {
      "epoch": 0.7986009909647334,
      "grad_norm": 0.3076333999633789,
      "learning_rate": 3.707336210278541e-05,
      "loss": 0.2276,
      "step": 1370
    },
    {
      "epoch": 0.8044301952783445,
      "grad_norm": 0.3123963177204132,
      "learning_rate": 3.697528442526481e-05,
      "loss": 0.2287,
      "step": 1380
    },
    {
      "epoch": 0.8102593995919557,
      "grad_norm": 0.3214288651943207,
      "learning_rate": 3.6877206747744216e-05,
      "loss": 0.2276,
      "step": 1390
    },
    {
      "epoch": 0.8160886039055669,
      "grad_norm": 0.294143408536911,
      "learning_rate": 3.677912907022362e-05,
      "loss": 0.2281,
      "step": 1400
    },
    {
      "epoch": 0.8160886039055669,
      "eval_loss": 0.1453082412481308,
      "eval_runtime": 91.961,
      "eval_samples_per_second": 376.41,
      "eval_steps_per_second": 47.053,
      "step": 1400
    },
    {
      "epoch": 0.821917808219178,
      "grad_norm": 0.2915715277194977,
      "learning_rate": 3.6681051392703024e-05,
      "loss": 0.2281,
      "step": 1410
    },
    {
      "epoch": 0.8277470125327893,
      "grad_norm": 0.28446081280708313,
      "learning_rate": 3.658297371518243e-05,
      "loss": 0.2221,
      "step": 1420
    },
    {
      "epoch": 0.8335762168464005,
      "grad_norm": 0.29199936985969543,
      "learning_rate": 3.648489603766183e-05,
      "loss": 0.2225,
      "step": 1430
    },
    {
      "epoch": 0.8394054211600117,
      "grad_norm": 0.3125315308570862,
      "learning_rate": 3.6386818360141236e-05,
      "loss": 0.2259,
      "step": 1440
    },
    {
      "epoch": 0.8452346254736228,
      "grad_norm": 0.309722363948822,
      "learning_rate": 3.628874068262064e-05,
      "loss": 0.2245,
      "step": 1450
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 0.2842015027999878,
      "learning_rate": 3.619066300510004e-05,
      "loss": 0.2235,
      "step": 1460
    },
    {
      "epoch": 0.8568930341008453,
      "grad_norm": 0.2941005527973175,
      "learning_rate": 3.609258532757944e-05,
      "loss": 0.2228,
      "step": 1470
    },
    {
      "epoch": 0.8627222384144564,
      "grad_norm": 0.30937206745147705,
      "learning_rate": 3.599450765005885e-05,
      "loss": 0.2189,
      "step": 1480
    },
    {
      "epoch": 0.8685514427280676,
      "grad_norm": 0.28543737530708313,
      "learning_rate": 3.5896429972538256e-05,
      "loss": 0.2173,
      "step": 1490
    },
    {
      "epoch": 0.8743806470416788,
      "grad_norm": 0.2754146456718445,
      "learning_rate": 3.5798352295017653e-05,
      "loss": 0.218,
      "step": 1500
    },
    {
      "epoch": 0.8743806470416788,
      "eval_loss": 0.13952594995498657,
      "eval_runtime": 92.04,
      "eval_samples_per_second": 376.087,
      "eval_steps_per_second": 47.012,
      "step": 1500
    },
    {
      "epoch": 0.88020985135529,
      "grad_norm": 0.2934216856956482,
      "learning_rate": 3.570027461749706e-05,
      "loss": 0.219,
      "step": 1510
    },
    {
      "epoch": 0.8860390556689012,
      "grad_norm": 0.2870826721191406,
      "learning_rate": 3.560219693997646e-05,
      "loss": 0.2164,
      "step": 1520
    },
    {
      "epoch": 0.8918682599825124,
      "grad_norm": 0.2976264953613281,
      "learning_rate": 3.5504119262455866e-05,
      "loss": 0.2207,
      "step": 1530
    },
    {
      "epoch": 0.8976974642961236,
      "grad_norm": 0.31050458550453186,
      "learning_rate": 3.540604158493527e-05,
      "loss": 0.215,
      "step": 1540
    },
    {
      "epoch": 0.9035266686097347,
      "grad_norm": 0.2835662066936493,
      "learning_rate": 3.5307963907414674e-05,
      "loss": 0.2156,
      "step": 1550
    },
    {
      "epoch": 0.909355872923346,
      "grad_norm": 0.288234680891037,
      "learning_rate": 3.520988622989408e-05,
      "loss": 0.2114,
      "step": 1560
    },
    {
      "epoch": 0.9151850772369572,
      "grad_norm": 0.2969256341457367,
      "learning_rate": 3.511180855237348e-05,
      "loss": 0.2087,
      "step": 1570
    },
    {
      "epoch": 0.9210142815505683,
      "grad_norm": 0.2730332612991333,
      "learning_rate": 3.5013730874852886e-05,
      "loss": 0.2098,
      "step": 1580
    },
    {
      "epoch": 0.9268434858641795,
      "grad_norm": 0.2874053716659546,
      "learning_rate": 3.491565319733229e-05,
      "loss": 0.2133,
      "step": 1590
    },
    {
      "epoch": 0.9326726901777908,
      "grad_norm": 0.2881523072719574,
      "learning_rate": 3.481757551981169e-05,
      "loss": 0.2106,
      "step": 1600
    },
    {
      "epoch": 0.9326726901777908,
      "eval_loss": 0.13434195518493652,
      "eval_runtime": 92.7132,
      "eval_samples_per_second": 373.356,
      "eval_steps_per_second": 46.671,
      "step": 1600
    },
    {
      "epoch": 0.938501894491402,
      "grad_norm": 0.28101846575737,
      "learning_rate": 3.47194978422911e-05,
      "loss": 0.2108,
      "step": 1610
    },
    {
      "epoch": 0.9443310988050131,
      "grad_norm": 0.2855300307273865,
      "learning_rate": 3.46214201647705e-05,
      "loss": 0.2111,
      "step": 1620
    },
    {
      "epoch": 0.9501603031186243,
      "grad_norm": 0.29567307233810425,
      "learning_rate": 3.4523342487249906e-05,
      "loss": 0.2088,
      "step": 1630
    },
    {
      "epoch": 0.9559895074322355,
      "grad_norm": 0.27828216552734375,
      "learning_rate": 3.442526480972931e-05,
      "loss": 0.2089,
      "step": 1640
    },
    {
      "epoch": 0.9618187117458467,
      "grad_norm": 0.2949428856372833,
      "learning_rate": 3.432718713220871e-05,
      "loss": 0.2065,
      "step": 1650
    },
    {
      "epoch": 0.9676479160594579,
      "grad_norm": 0.2828122079372406,
      "learning_rate": 3.422910945468811e-05,
      "loss": 0.2101,
      "step": 1660
    },
    {
      "epoch": 0.9734771203730691,
      "grad_norm": 0.27810293436050415,
      "learning_rate": 3.4131031777167515e-05,
      "loss": 0.2041,
      "step": 1670
    },
    {
      "epoch": 0.9793063246866802,
      "grad_norm": 0.28853732347488403,
      "learning_rate": 3.4032954099646926e-05,
      "loss": 0.21,
      "step": 1680
    },
    {
      "epoch": 0.9851355290002914,
      "grad_norm": 0.29378342628479004,
      "learning_rate": 3.393487642212633e-05,
      "loss": 0.2049,
      "step": 1690
    },
    {
      "epoch": 0.9909647333139027,
      "grad_norm": 0.2809070646762848,
      "learning_rate": 3.383679874460573e-05,
      "loss": 0.2048,
      "step": 1700
    },
    {
      "epoch": 0.9909647333139027,
      "eval_loss": 0.13013845682144165,
      "eval_runtime": 92.0014,
      "eval_samples_per_second": 376.244,
      "eval_steps_per_second": 47.032,
      "step": 1700
    },
    {
      "epoch": 0.9967939376275139,
      "grad_norm": 0.2983750104904175,
      "learning_rate": 3.373872106708513e-05,
      "loss": 0.203,
      "step": 1710
    },
    {
      "epoch": 1.0023316817254444,
      "grad_norm": 0.3224446475505829,
      "learning_rate": 3.3640643389564536e-05,
      "loss": 0.1936,
      "step": 1720
    },
    {
      "epoch": 1.0081608860390556,
      "grad_norm": 0.2684609591960907,
      "learning_rate": 3.354256571204394e-05,
      "loss": 0.1966,
      "step": 1730
    },
    {
      "epoch": 1.0139900903526669,
      "grad_norm": 0.29175007343292236,
      "learning_rate": 3.3444488034523344e-05,
      "loss": 0.1975,
      "step": 1740
    },
    {
      "epoch": 1.019819294666278,
      "grad_norm": 0.29054203629493713,
      "learning_rate": 3.334641035700275e-05,
      "loss": 0.1991,
      "step": 1750
    },
    {
      "epoch": 1.0256484989798893,
      "grad_norm": 0.2799953520298004,
      "learning_rate": 3.324833267948215e-05,
      "loss": 0.1964,
      "step": 1760
    },
    {
      "epoch": 1.0314777032935005,
      "grad_norm": 0.2900519371032715,
      "learning_rate": 3.3150255001961556e-05,
      "loss": 0.1953,
      "step": 1770
    },
    {
      "epoch": 1.0373069076071115,
      "grad_norm": 0.28152114152908325,
      "learning_rate": 3.305217732444096e-05,
      "loss": 0.1995,
      "step": 1780
    },
    {
      "epoch": 1.0431361119207228,
      "grad_norm": 0.26587289571762085,
      "learning_rate": 3.2954099646920364e-05,
      "loss": 0.1939,
      "step": 1790
    },
    {
      "epoch": 1.048965316234334,
      "grad_norm": 0.2969556152820587,
      "learning_rate": 3.285602196939976e-05,
      "loss": 0.1979,
      "step": 1800
    },
    {
      "epoch": 1.048965316234334,
      "eval_loss": 0.12614959478378296,
      "eval_runtime": 89.9907,
      "eval_samples_per_second": 384.651,
      "eval_steps_per_second": 48.083,
      "step": 1800
    },
    {
      "epoch": 1.0547945205479452,
      "grad_norm": 0.29665085673332214,
      "learning_rate": 3.275794429187917e-05,
      "loss": 0.1973,
      "step": 1810
    },
    {
      "epoch": 1.0606237248615564,
      "grad_norm": 0.27347609400749207,
      "learning_rate": 3.2659866614358576e-05,
      "loss": 0.191,
      "step": 1820
    },
    {
      "epoch": 1.0664529291751677,
      "grad_norm": 0.286410391330719,
      "learning_rate": 3.256178893683798e-05,
      "loss": 0.1924,
      "step": 1830
    },
    {
      "epoch": 1.0722821334887789,
      "grad_norm": 0.29005274176597595,
      "learning_rate": 3.2463711259317384e-05,
      "loss": 0.1939,
      "step": 1840
    },
    {
      "epoch": 1.0781113378023899,
      "grad_norm": 0.28636351227760315,
      "learning_rate": 3.236563358179678e-05,
      "loss": 0.1936,
      "step": 1850
    },
    {
      "epoch": 1.083940542116001,
      "grad_norm": 0.2729344666004181,
      "learning_rate": 3.2267555904276185e-05,
      "loss": 0.1946,
      "step": 1860
    },
    {
      "epoch": 1.0897697464296123,
      "grad_norm": 0.28317520022392273,
      "learning_rate": 3.216947822675559e-05,
      "loss": 0.1922,
      "step": 1870
    },
    {
      "epoch": 1.0955989507432236,
      "grad_norm": 0.28050997853279114,
      "learning_rate": 3.2071400549235e-05,
      "loss": 0.1914,
      "step": 1880
    },
    {
      "epoch": 1.1014281550568348,
      "grad_norm": 0.27711889147758484,
      "learning_rate": 3.19733228717144e-05,
      "loss": 0.1872,
      "step": 1890
    },
    {
      "epoch": 1.107257359370446,
      "grad_norm": 0.2835142910480499,
      "learning_rate": 3.18752451941938e-05,
      "loss": 0.1938,
      "step": 1900
    },
    {
      "epoch": 1.107257359370446,
      "eval_loss": 0.12187056988477707,
      "eval_runtime": 92.0869,
      "eval_samples_per_second": 375.895,
      "eval_steps_per_second": 46.988,
      "step": 1900
    },
    {
      "epoch": 1.1130865636840572,
      "grad_norm": 0.28185513615608215,
      "learning_rate": 3.1777167516673206e-05,
      "loss": 0.1893,
      "step": 1910
    },
    {
      "epoch": 1.1189157679976682,
      "grad_norm": 0.26616141200065613,
      "learning_rate": 3.167908983915261e-05,
      "loss": 0.191,
      "step": 1920
    },
    {
      "epoch": 1.1247449723112795,
      "grad_norm": 0.27427124977111816,
      "learning_rate": 3.1581012161632014e-05,
      "loss": 0.1894,
      "step": 1930
    },
    {
      "epoch": 1.1305741766248907,
      "grad_norm": 0.27347856760025024,
      "learning_rate": 3.148293448411142e-05,
      "loss": 0.1888,
      "step": 1940
    },
    {
      "epoch": 1.136403380938502,
      "grad_norm": 0.28896719217300415,
      "learning_rate": 3.138485680659082e-05,
      "loss": 0.1883,
      "step": 1950
    },
    {
      "epoch": 1.1422325852521131,
      "grad_norm": 0.2793254256248474,
      "learning_rate": 3.1286779129070226e-05,
      "loss": 0.1907,
      "step": 1960
    },
    {
      "epoch": 1.1480617895657244,
      "grad_norm": 0.2677293121814728,
      "learning_rate": 3.118870145154963e-05,
      "loss": 0.1844,
      "step": 1970
    },
    {
      "epoch": 1.1538909938793354,
      "grad_norm": 0.25899460911750793,
      "learning_rate": 3.1090623774029034e-05,
      "loss": 0.185,
      "step": 1980
    },
    {
      "epoch": 1.1597201981929466,
      "grad_norm": 0.2865290641784668,
      "learning_rate": 3.099254609650844e-05,
      "loss": 0.1846,
      "step": 1990
    },
    {
      "epoch": 1.1655494025065578,
      "grad_norm": 0.27059486508369446,
      "learning_rate": 3.0894468418987835e-05,
      "loss": 0.1857,
      "step": 2000
    },
    {
      "epoch": 1.1655494025065578,
      "eval_loss": 0.11860565096139908,
      "eval_runtime": 92.4158,
      "eval_samples_per_second": 374.557,
      "eval_steps_per_second": 46.821,
      "step": 2000
    },
    {
      "epoch": 1.171378606820169,
      "grad_norm": 0.28290605545043945,
      "learning_rate": 3.0796390741467246e-05,
      "loss": 0.185,
      "step": 2010
    },
    {
      "epoch": 1.1772078111337803,
      "grad_norm": 0.26049885153770447,
      "learning_rate": 3.069831306394665e-05,
      "loss": 0.188,
      "step": 2020
    },
    {
      "epoch": 1.1830370154473915,
      "grad_norm": 0.2773285210132599,
      "learning_rate": 3.0600235386426054e-05,
      "loss": 0.186,
      "step": 2030
    },
    {
      "epoch": 1.1888662197610027,
      "grad_norm": 0.2858315408229828,
      "learning_rate": 3.0502157708905455e-05,
      "loss": 0.1826,
      "step": 2040
    },
    {
      "epoch": 1.194695424074614,
      "grad_norm": 0.2862517833709717,
      "learning_rate": 3.040408003138486e-05,
      "loss": 0.1867,
      "step": 2050
    },
    {
      "epoch": 1.200524628388225,
      "grad_norm": 0.27242496609687805,
      "learning_rate": 3.030600235386426e-05,
      "loss": 0.1872,
      "step": 2060
    },
    {
      "epoch": 1.2063538327018362,
      "grad_norm": 0.29873037338256836,
      "learning_rate": 3.0207924676343664e-05,
      "loss": 0.1848,
      "step": 2070
    },
    {
      "epoch": 1.2121830370154474,
      "grad_norm": 0.28996145725250244,
      "learning_rate": 3.010984699882307e-05,
      "loss": 0.184,
      "step": 2080
    },
    {
      "epoch": 1.2180122413290586,
      "grad_norm": 0.28113919496536255,
      "learning_rate": 3.0011769321302475e-05,
      "loss": 0.1807,
      "step": 2090
    },
    {
      "epoch": 1.2238414456426698,
      "grad_norm": 0.2691393494606018,
      "learning_rate": 2.9913691643781876e-05,
      "loss": 0.1809,
      "step": 2100
    },
    {
      "epoch": 1.2238414456426698,
      "eval_loss": 0.11506355553865433,
      "eval_runtime": 93.6857,
      "eval_samples_per_second": 369.48,
      "eval_steps_per_second": 46.186,
      "step": 2100
    },
    {
      "epoch": 1.229670649956281,
      "grad_norm": 0.2538716793060303,
      "learning_rate": 2.981561396626128e-05,
      "loss": 0.1843,
      "step": 2110
    },
    {
      "epoch": 1.235499854269892,
      "grad_norm": 0.28166189789772034,
      "learning_rate": 2.9717536288740684e-05,
      "loss": 0.1829,
      "step": 2120
    },
    {
      "epoch": 1.2413290585835033,
      "grad_norm": 0.26843416690826416,
      "learning_rate": 2.9619458611220084e-05,
      "loss": 0.1791,
      "step": 2130
    },
    {
      "epoch": 1.2471582628971145,
      "grad_norm": 0.25422191619873047,
      "learning_rate": 2.9521380933699495e-05,
      "loss": 0.1818,
      "step": 2140
    },
    {
      "epoch": 1.2529874672107257,
      "grad_norm": 0.2763351798057556,
      "learning_rate": 2.9423303256178896e-05,
      "loss": 0.1795,
      "step": 2150
    },
    {
      "epoch": 1.258816671524337,
      "grad_norm": 0.26476043462753296,
      "learning_rate": 2.93252255786583e-05,
      "loss": 0.1816,
      "step": 2160
    },
    {
      "epoch": 1.2646458758379482,
      "grad_norm": 0.27810901403427124,
      "learning_rate": 2.9227147901137704e-05,
      "loss": 0.1774,
      "step": 2170
    },
    {
      "epoch": 1.2704750801515594,
      "grad_norm": 0.2666003406047821,
      "learning_rate": 2.9129070223617105e-05,
      "loss": 0.1785,
      "step": 2180
    },
    {
      "epoch": 1.2763042844651706,
      "grad_norm": 0.2859840393066406,
      "learning_rate": 2.903099254609651e-05,
      "loss": 0.179,
      "step": 2190
    },
    {
      "epoch": 1.2821334887787816,
      "grad_norm": 0.2630036473274231,
      "learning_rate": 2.8932914868575913e-05,
      "loss": 0.1823,
      "step": 2200
    },
    {
      "epoch": 1.2821334887787816,
      "eval_loss": 0.11222986876964569,
      "eval_runtime": 92.9656,
      "eval_samples_per_second": 372.342,
      "eval_steps_per_second": 46.544,
      "step": 2200
    },
    {
      "epoch": 1.2879626930923929,
      "grad_norm": 0.2734869718551636,
      "learning_rate": 2.883483719105532e-05,
      "loss": 0.1773,
      "step": 2210
    },
    {
      "epoch": 1.293791897406004,
      "grad_norm": 0.27810031175613403,
      "learning_rate": 2.873675951353472e-05,
      "loss": 0.176,
      "step": 2220
    },
    {
      "epoch": 1.2996211017196153,
      "grad_norm": 0.27314722537994385,
      "learning_rate": 2.8638681836014125e-05,
      "loss": 0.1813,
      "step": 2230
    },
    {
      "epoch": 1.3054503060332265,
      "grad_norm": 0.24465426802635193,
      "learning_rate": 2.854060415849353e-05,
      "loss": 0.1776,
      "step": 2240
    },
    {
      "epoch": 1.3112795103468375,
      "grad_norm": 0.2704048156738281,
      "learning_rate": 2.844252648097293e-05,
      "loss": 0.1762,
      "step": 2250
    },
    {
      "epoch": 1.3171087146604488,
      "grad_norm": 0.27158090472221375,
      "learning_rate": 2.8344448803452334e-05,
      "loss": 0.1794,
      "step": 2260
    },
    {
      "epoch": 1.32293791897406,
      "grad_norm": 0.2576133906841278,
      "learning_rate": 2.824637112593174e-05,
      "loss": 0.1768,
      "step": 2270
    },
    {
      "epoch": 1.3287671232876712,
      "grad_norm": 0.25775328278541565,
      "learning_rate": 2.8148293448411145e-05,
      "loss": 0.1775,
      "step": 2280
    },
    {
      "epoch": 1.3345963276012824,
      "grad_norm": 0.27636951208114624,
      "learning_rate": 2.805021577089055e-05,
      "loss": 0.177,
      "step": 2290
    },
    {
      "epoch": 1.3404255319148937,
      "grad_norm": 0.2566342353820801,
      "learning_rate": 2.795213809336995e-05,
      "loss": 0.1744,
      "step": 2300
    },
    {
      "epoch": 1.3404255319148937,
      "eval_loss": 0.10906492918729782,
      "eval_runtime": 88.1169,
      "eval_samples_per_second": 392.831,
      "eval_steps_per_second": 49.105,
      "step": 2300
    },
    {
      "epoch": 1.346254736228505,
      "grad_norm": 0.282423734664917,
      "learning_rate": 2.7854060415849354e-05,
      "loss": 0.1759,
      "step": 2310
    },
    {
      "epoch": 1.3520839405421161,
      "grad_norm": 0.27475985884666443,
      "learning_rate": 2.7755982738328758e-05,
      "loss": 0.1748,
      "step": 2320
    },
    {
      "epoch": 1.3579131448557271,
      "grad_norm": 0.2795245051383972,
      "learning_rate": 2.765790506080816e-05,
      "loss": 0.1752,
      "step": 2330
    },
    {
      "epoch": 1.3637423491693383,
      "grad_norm": 0.2642580270767212,
      "learning_rate": 2.7559827383287566e-05,
      "loss": 0.173,
      "step": 2340
    },
    {
      "epoch": 1.3695715534829496,
      "grad_norm": 0.269076406955719,
      "learning_rate": 2.746174970576697e-05,
      "loss": 0.1723,
      "step": 2350
    },
    {
      "epoch": 1.3754007577965608,
      "grad_norm": 0.25904640555381775,
      "learning_rate": 2.7363672028246374e-05,
      "loss": 0.1753,
      "step": 2360
    },
    {
      "epoch": 1.381229962110172,
      "grad_norm": 0.2653832733631134,
      "learning_rate": 2.7265594350725775e-05,
      "loss": 0.176,
      "step": 2370
    },
    {
      "epoch": 1.387059166423783,
      "grad_norm": 0.2610279321670532,
      "learning_rate": 2.716751667320518e-05,
      "loss": 0.1729,
      "step": 2380
    },
    {
      "epoch": 1.3928883707373942,
      "grad_norm": 0.25328803062438965,
      "learning_rate": 2.7069438995684583e-05,
      "loss": 0.1725,
      "step": 2390
    },
    {
      "epoch": 1.3987175750510055,
      "grad_norm": 0.2687666416168213,
      "learning_rate": 2.6971361318163983e-05,
      "loss": 0.1739,
      "step": 2400
    },
    {
      "epoch": 1.3987175750510055,
      "eval_loss": 0.10689388960599899,
      "eval_runtime": 91.6448,
      "eval_samples_per_second": 377.708,
      "eval_steps_per_second": 47.215,
      "step": 2400
    },
    {
      "epoch": 1.4045467793646167,
      "grad_norm": 0.26563966274261475,
      "learning_rate": 2.6873283640643394e-05,
      "loss": 0.1771,
      "step": 2410
    },
    {
      "epoch": 1.410375983678228,
      "grad_norm": 0.2648673951625824,
      "learning_rate": 2.6775205963122795e-05,
      "loss": 0.1744,
      "step": 2420
    },
    {
      "epoch": 1.4162051879918391,
      "grad_norm": 0.2687324285507202,
      "learning_rate": 2.66771282856022e-05,
      "loss": 0.172,
      "step": 2430
    },
    {
      "epoch": 1.4220343923054504,
      "grad_norm": 0.2637385427951813,
      "learning_rate": 2.6579050608081603e-05,
      "loss": 0.172,
      "step": 2440
    },
    {
      "epoch": 1.4278635966190616,
      "grad_norm": 0.26356497406959534,
      "learning_rate": 2.6480972930561004e-05,
      "loss": 0.1698,
      "step": 2450
    },
    {
      "epoch": 1.4336928009326728,
      "grad_norm": 0.25639086961746216,
      "learning_rate": 2.6382895253040408e-05,
      "loss": 0.1671,
      "step": 2460
    },
    {
      "epoch": 1.4395220052462838,
      "grad_norm": 0.2707938849925995,
      "learning_rate": 2.6284817575519815e-05,
      "loss": 0.1719,
      "step": 2470
    },
    {
      "epoch": 1.445351209559895,
      "grad_norm": 0.31082966923713684,
      "learning_rate": 2.618673989799922e-05,
      "loss": 0.1699,
      "step": 2480
    },
    {
      "epoch": 1.4511804138735063,
      "grad_norm": 0.2426415979862213,
      "learning_rate": 2.608866222047862e-05,
      "loss": 0.1673,
      "step": 2490
    },
    {
      "epoch": 1.4570096181871175,
      "grad_norm": 0.2464362382888794,
      "learning_rate": 2.5990584542958024e-05,
      "loss": 0.1702,
      "step": 2500
    },
    {
      "epoch": 1.4570096181871175,
      "eval_loss": 0.1044773980975151,
      "eval_runtime": 92.0833,
      "eval_samples_per_second": 375.91,
      "eval_steps_per_second": 46.99,
      "step": 2500
    },
    {
      "epoch": 1.4628388225007287,
      "grad_norm": 0.26636171340942383,
      "learning_rate": 2.5892506865437428e-05,
      "loss": 0.1685,
      "step": 2510
    },
    {
      "epoch": 1.4686680268143397,
      "grad_norm": 0.26779618859291077,
      "learning_rate": 2.579442918791683e-05,
      "loss": 0.1642,
      "step": 2520
    },
    {
      "epoch": 1.474497231127951,
      "grad_norm": 0.25206589698791504,
      "learning_rate": 2.5696351510396233e-05,
      "loss": 0.1666,
      "step": 2530
    },
    {
      "epoch": 1.4803264354415622,
      "grad_norm": 0.24834656715393066,
      "learning_rate": 2.559827383287564e-05,
      "loss": 0.1707,
      "step": 2540
    },
    {
      "epoch": 1.4861556397551734,
      "grad_norm": 0.264831006526947,
      "learning_rate": 2.5500196155355044e-05,
      "loss": 0.1679,
      "step": 2550
    },
    {
      "epoch": 1.4919848440687846,
      "grad_norm": 0.2785678207874298,
      "learning_rate": 2.5402118477834448e-05,
      "loss": 0.1663,
      "step": 2560
    },
    {
      "epoch": 1.4978140483823958,
      "grad_norm": 0.2578992247581482,
      "learning_rate": 2.530404080031385e-05,
      "loss": 0.1672,
      "step": 2570
    },
    {
      "epoch": 1.503643252696007,
      "grad_norm": 0.2561148703098297,
      "learning_rate": 2.5205963122793253e-05,
      "loss": 0.1677,
      "step": 2580
    },
    {
      "epoch": 1.5094724570096183,
      "grad_norm": 0.24595539271831512,
      "learning_rate": 2.5107885445272657e-05,
      "loss": 0.1665,
      "step": 2590
    },
    {
      "epoch": 1.5153016613232295,
      "grad_norm": 0.2577636241912842,
      "learning_rate": 2.5009807767752057e-05,
      "loss": 0.1671,
      "step": 2600
    },
    {
      "epoch": 1.5153016613232295,
      "eval_loss": 0.10233201831579208,
      "eval_runtime": 91.9768,
      "eval_samples_per_second": 376.345,
      "eval_steps_per_second": 47.044,
      "step": 2600
    },
    {
      "epoch": 1.5211308656368405,
      "grad_norm": 0.2601247727870941,
      "learning_rate": 2.4911730090231465e-05,
      "loss": 0.1634,
      "step": 2610
    },
    {
      "epoch": 1.5269600699504517,
      "grad_norm": 0.24888010323047638,
      "learning_rate": 2.481365241271087e-05,
      "loss": 0.1638,
      "step": 2620
    },
    {
      "epoch": 1.532789274264063,
      "grad_norm": 0.26849570870399475,
      "learning_rate": 2.4715574735190273e-05,
      "loss": 0.1684,
      "step": 2630
    },
    {
      "epoch": 1.5386184785776742,
      "grad_norm": 0.2639648914337158,
      "learning_rate": 2.4617497057669674e-05,
      "loss": 0.1662,
      "step": 2640
    },
    {
      "epoch": 1.5444476828912852,
      "grad_norm": 0.2650565207004547,
      "learning_rate": 2.4519419380149078e-05,
      "loss": 0.1655,
      "step": 2650
    },
    {
      "epoch": 1.5502768872048964,
      "grad_norm": 0.24833117425441742,
      "learning_rate": 2.4421341702628485e-05,
      "loss": 0.1657,
      "step": 2660
    },
    {
      "epoch": 1.5561060915185077,
      "grad_norm": 0.2526870369911194,
      "learning_rate": 2.4323264025107886e-05,
      "loss": 0.1636,
      "step": 2670
    },
    {
      "epoch": 1.5619352958321189,
      "grad_norm": 0.2620363235473633,
      "learning_rate": 2.422518634758729e-05,
      "loss": 0.1631,
      "step": 2680
    },
    {
      "epoch": 1.56776450014573,
      "grad_norm": 0.2521420419216156,
      "learning_rate": 2.4127108670066694e-05,
      "loss": 0.1669,
      "step": 2690
    },
    {
      "epoch": 1.5735937044593413,
      "grad_norm": 0.24986985325813293,
      "learning_rate": 2.4029030992546098e-05,
      "loss": 0.1642,
      "step": 2700
    },
    {
      "epoch": 1.5735937044593413,
      "eval_loss": 0.1002350002527237,
      "eval_runtime": 92.3603,
      "eval_samples_per_second": 374.782,
      "eval_steps_per_second": 46.849,
      "step": 2700
    },
    {
      "epoch": 1.5794229087729525,
      "grad_norm": 0.23955479264259338,
      "learning_rate": 2.3930953315025502e-05,
      "loss": 0.1662,
      "step": 2710
    },
    {
      "epoch": 1.5852521130865638,
      "grad_norm": 0.2519936263561249,
      "learning_rate": 2.3832875637504906e-05,
      "loss": 0.163,
      "step": 2720
    },
    {
      "epoch": 1.591081317400175,
      "grad_norm": 0.26689696311950684,
      "learning_rate": 2.373479795998431e-05,
      "loss": 0.1626,
      "step": 2730
    },
    {
      "epoch": 1.5969105217137862,
      "grad_norm": 0.24827907979488373,
      "learning_rate": 2.363672028246371e-05,
      "loss": 0.1614,
      "step": 2740
    },
    {
      "epoch": 1.6027397260273972,
      "grad_norm": 0.25183817744255066,
      "learning_rate": 2.3538642604943118e-05,
      "loss": 0.16,
      "step": 2750
    },
    {
      "epoch": 1.6085689303410085,
      "grad_norm": 0.24293620884418488,
      "learning_rate": 2.344056492742252e-05,
      "loss": 0.161,
      "step": 2760
    },
    {
      "epoch": 1.6143981346546197,
      "grad_norm": 0.2571193277835846,
      "learning_rate": 2.3342487249901923e-05,
      "loss": 0.1656,
      "step": 2770
    },
    {
      "epoch": 1.6202273389682307,
      "grad_norm": 0.2707139551639557,
      "learning_rate": 2.3244409572381327e-05,
      "loss": 0.1621,
      "step": 2780
    },
    {
      "epoch": 1.626056543281842,
      "grad_norm": 0.2700357735157013,
      "learning_rate": 2.314633189486073e-05,
      "loss": 0.1628,
      "step": 2790
    },
    {
      "epoch": 1.6318857475954531,
      "grad_norm": 0.26740798354148865,
      "learning_rate": 2.3048254217340135e-05,
      "loss": 0.1628,
      "step": 2800
    },
    {
      "epoch": 1.6318857475954531,
      "eval_loss": 0.09878239035606384,
      "eval_runtime": 88.3013,
      "eval_samples_per_second": 392.01,
      "eval_steps_per_second": 49.003,
      "step": 2800
    },
    {
      "epoch": 1.6377149519090644,
      "grad_norm": 0.24644717574119568,
      "learning_rate": 2.295017653981954e-05,
      "loss": 0.1619,
      "step": 2810
    },
    {
      "epoch": 1.6435441562226756,
      "grad_norm": 0.26815706491470337,
      "learning_rate": 2.2852098862298943e-05,
      "loss": 0.1642,
      "step": 2820
    },
    {
      "epoch": 1.6493733605362868,
      "grad_norm": 0.2577410340309143,
      "learning_rate": 2.2754021184778347e-05,
      "loss": 0.1599,
      "step": 2830
    },
    {
      "epoch": 1.655202564849898,
      "grad_norm": 0.26203662157058716,
      "learning_rate": 2.2655943507257748e-05,
      "loss": 0.1596,
      "step": 2840
    },
    {
      "epoch": 1.6610317691635093,
      "grad_norm": 0.24170763790607452,
      "learning_rate": 2.2557865829737155e-05,
      "loss": 0.1609,
      "step": 2850
    },
    {
      "epoch": 1.6668609734771205,
      "grad_norm": 0.26122429966926575,
      "learning_rate": 2.2459788152216556e-05,
      "loss": 0.1605,
      "step": 2860
    },
    {
      "epoch": 1.6726901777907317,
      "grad_norm": 0.24759595096111298,
      "learning_rate": 2.236171047469596e-05,
      "loss": 0.1603,
      "step": 2870
    },
    {
      "epoch": 1.6785193821043427,
      "grad_norm": 0.24774247407913208,
      "learning_rate": 2.2263632797175364e-05,
      "loss": 0.1623,
      "step": 2880
    },
    {
      "epoch": 1.684348586417954,
      "grad_norm": 0.25158455967903137,
      "learning_rate": 2.2165555119654768e-05,
      "loss": 0.16,
      "step": 2890
    },
    {
      "epoch": 1.6901777907315652,
      "grad_norm": 0.2556194067001343,
      "learning_rate": 2.2067477442134172e-05,
      "loss": 0.1555,
      "step": 2900
    },
    {
      "epoch": 1.6901777907315652,
      "eval_loss": 0.09742367267608643,
      "eval_runtime": 92.6681,
      "eval_samples_per_second": 373.537,
      "eval_steps_per_second": 46.694,
      "step": 2900
    },
    {
      "epoch": 1.6960069950451764,
      "grad_norm": 0.24574285745620728,
      "learning_rate": 2.1969399764613573e-05,
      "loss": 0.1592,
      "step": 2910
    },
    {
      "epoch": 1.7018361993587874,
      "grad_norm": 0.26289644837379456,
      "learning_rate": 2.187132208709298e-05,
      "loss": 0.1605,
      "step": 2920
    },
    {
      "epoch": 1.7076654036723986,
      "grad_norm": 0.2562645971775055,
      "learning_rate": 2.1773244409572384e-05,
      "loss": 0.1592,
      "step": 2930
    },
    {
      "epoch": 1.7134946079860098,
      "grad_norm": 0.2542620897293091,
      "learning_rate": 2.1675166732051785e-05,
      "loss": 0.1613,
      "step": 2940
    },
    {
      "epoch": 1.719323812299621,
      "grad_norm": 0.2610343396663666,
      "learning_rate": 2.1577089054531192e-05,
      "loss": 0.1587,
      "step": 2950
    },
    {
      "epoch": 1.7251530166132323,
      "grad_norm": 0.26618942618370056,
      "learning_rate": 2.1479011377010593e-05,
      "loss": 0.1574,
      "step": 2960
    },
    {
      "epoch": 1.7309822209268435,
      "grad_norm": 0.2790577709674835,
      "learning_rate": 2.1380933699489997e-05,
      "loss": 0.1584,
      "step": 2970
    },
    {
      "epoch": 1.7368114252404547,
      "grad_norm": 0.2464715987443924,
      "learning_rate": 2.12828560219694e-05,
      "loss": 0.1588,
      "step": 2980
    },
    {
      "epoch": 1.742640629554066,
      "grad_norm": 0.24825455248355865,
      "learning_rate": 2.1184778344448805e-05,
      "loss": 0.1588,
      "step": 2990
    },
    {
      "epoch": 1.7484698338676772,
      "grad_norm": 0.2487979382276535,
      "learning_rate": 2.108670066692821e-05,
      "loss": 0.1598,
      "step": 3000
    },
    {
      "epoch": 1.7484698338676772,
      "eval_loss": 0.09527680277824402,
      "eval_runtime": 93.1935,
      "eval_samples_per_second": 371.431,
      "eval_steps_per_second": 46.43,
      "step": 3000
    },
    {
      "epoch": 1.7542990381812884,
      "grad_norm": 0.24863016605377197,
      "learning_rate": 2.098862298940761e-05,
      "loss": 0.1631,
      "step": 3010
    },
    {
      "epoch": 1.7601282424948994,
      "grad_norm": 0.2715972661972046,
      "learning_rate": 2.0890545311887017e-05,
      "loss": 0.1574,
      "step": 3020
    },
    {
      "epoch": 1.7659574468085106,
      "grad_norm": 0.24122363328933716,
      "learning_rate": 2.0792467634366418e-05,
      "loss": 0.1573,
      "step": 3030
    },
    {
      "epoch": 1.7717866511221219,
      "grad_norm": 0.25893163681030273,
      "learning_rate": 2.0694389956845822e-05,
      "loss": 0.1573,
      "step": 3040
    },
    {
      "epoch": 1.7776158554357329,
      "grad_norm": 0.26518160104751587,
      "learning_rate": 2.059631227932523e-05,
      "loss": 0.1569,
      "step": 3050
    },
    {
      "epoch": 1.783445059749344,
      "grad_norm": 0.26443740725517273,
      "learning_rate": 2.049823460180463e-05,
      "loss": 0.1548,
      "step": 3060
    },
    {
      "epoch": 1.7892742640629553,
      "grad_norm": 0.2457968294620514,
      "learning_rate": 2.0400156924284034e-05,
      "loss": 0.1575,
      "step": 3070
    },
    {
      "epoch": 1.7951034683765665,
      "grad_norm": 0.26688116788864136,
      "learning_rate": 2.0302079246763438e-05,
      "loss": 0.1575,
      "step": 3080
    },
    {
      "epoch": 1.8009326726901778,
      "grad_norm": 0.235088050365448,
      "learning_rate": 2.0204001569242842e-05,
      "loss": 0.154,
      "step": 3090
    },
    {
      "epoch": 1.806761877003789,
      "grad_norm": 0.2719249725341797,
      "learning_rate": 2.0105923891722246e-05,
      "loss": 0.1538,
      "step": 3100
    },
    {
      "epoch": 1.806761877003789,
      "eval_loss": 0.09391696751117706,
      "eval_runtime": 92.2305,
      "eval_samples_per_second": 375.31,
      "eval_steps_per_second": 46.915,
      "step": 3100
    },
    {
      "epoch": 1.8125910813174002,
      "grad_norm": 0.2519148588180542,
      "learning_rate": 2.0007846214201647e-05,
      "loss": 0.1502,
      "step": 3110
    },
    {
      "epoch": 1.8184202856310114,
      "grad_norm": 0.2500374913215637,
      "learning_rate": 1.9909768536681054e-05,
      "loss": 0.1572,
      "step": 3120
    },
    {
      "epoch": 1.8242494899446227,
      "grad_norm": 0.253163605928421,
      "learning_rate": 1.9811690859160455e-05,
      "loss": 0.1536,
      "step": 3130
    },
    {
      "epoch": 1.8300786942582339,
      "grad_norm": 0.25078991055488586,
      "learning_rate": 1.971361318163986e-05,
      "loss": 0.154,
      "step": 3140
    },
    {
      "epoch": 1.835907898571845,
      "grad_norm": 0.27124178409576416,
      "learning_rate": 1.9615535504119266e-05,
      "loss": 0.1547,
      "step": 3150
    },
    {
      "epoch": 1.8417371028854561,
      "grad_norm": 0.24117986857891083,
      "learning_rate": 1.9517457826598667e-05,
      "loss": 0.1508,
      "step": 3160
    },
    {
      "epoch": 1.8475663071990673,
      "grad_norm": 0.25705066323280334,
      "learning_rate": 1.941938014907807e-05,
      "loss": 0.153,
      "step": 3170
    },
    {
      "epoch": 1.8533955115126786,
      "grad_norm": 0.25593268871307373,
      "learning_rate": 1.932130247155747e-05,
      "loss": 0.1558,
      "step": 3180
    },
    {
      "epoch": 1.8592247158262896,
      "grad_norm": 0.24709978699684143,
      "learning_rate": 1.922322479403688e-05,
      "loss": 0.1516,
      "step": 3190
    },
    {
      "epoch": 1.8650539201399008,
      "grad_norm": 0.24341575801372528,
      "learning_rate": 1.9125147116516283e-05,
      "loss": 0.1528,
      "step": 3200
    },
    {
      "epoch": 1.8650539201399008,
      "eval_loss": 0.09234657883644104,
      "eval_runtime": 92.1328,
      "eval_samples_per_second": 375.708,
      "eval_steps_per_second": 46.965,
      "step": 3200
    },
    {
      "epoch": 1.870883124453512,
      "grad_norm": 0.24365997314453125,
      "learning_rate": 1.9027069438995684e-05,
      "loss": 0.1538,
      "step": 3210
    },
    {
      "epoch": 1.8767123287671232,
      "grad_norm": 0.24902789294719696,
      "learning_rate": 1.892899176147509e-05,
      "loss": 0.1542,
      "step": 3220
    },
    {
      "epoch": 1.8825415330807345,
      "grad_norm": 0.2464718073606491,
      "learning_rate": 1.8830914083954492e-05,
      "loss": 0.1535,
      "step": 3230
    },
    {
      "epoch": 1.8883707373943457,
      "grad_norm": 0.23931197822093964,
      "learning_rate": 1.8732836406433896e-05,
      "loss": 0.1516,
      "step": 3240
    },
    {
      "epoch": 1.894199941707957,
      "grad_norm": 0.25612807273864746,
      "learning_rate": 1.86347587289133e-05,
      "loss": 0.1516,
      "step": 3250
    },
    {
      "epoch": 1.9000291460215681,
      "grad_norm": 0.24141694605350494,
      "learning_rate": 1.8536681051392704e-05,
      "loss": 0.154,
      "step": 3260
    },
    {
      "epoch": 1.9058583503351794,
      "grad_norm": 0.23369602859020233,
      "learning_rate": 1.8438603373872108e-05,
      "loss": 0.154,
      "step": 3270
    },
    {
      "epoch": 1.9116875546487906,
      "grad_norm": 0.23104406893253326,
      "learning_rate": 1.8340525696351512e-05,
      "loss": 0.1528,
      "step": 3280
    },
    {
      "epoch": 1.9175167589624016,
      "grad_norm": 0.25491973757743835,
      "learning_rate": 1.8242448018830916e-05,
      "loss": 0.1503,
      "step": 3290
    },
    {
      "epoch": 1.9233459632760128,
      "grad_norm": 0.24583645164966583,
      "learning_rate": 1.814437034131032e-05,
      "loss": 0.1501,
      "step": 3300
    },
    {
      "epoch": 1.9233459632760128,
      "eval_loss": 0.09119102358818054,
      "eval_runtime": 88.7494,
      "eval_samples_per_second": 390.031,
      "eval_steps_per_second": 48.755,
      "step": 3300
    },
    {
      "epoch": 1.929175167589624,
      "grad_norm": 0.24166704714298248,
      "learning_rate": 1.804629266378972e-05,
      "loss": 0.1525,
      "step": 3310
    },
    {
      "epoch": 1.935004371903235,
      "grad_norm": 0.2456631362438202,
      "learning_rate": 1.7948214986269128e-05,
      "loss": 0.1513,
      "step": 3320
    },
    {
      "epoch": 1.9408335762168463,
      "grad_norm": 0.24742566049098969,
      "learning_rate": 1.785013730874853e-05,
      "loss": 0.1533,
      "step": 3330
    },
    {
      "epoch": 1.9466627805304575,
      "grad_norm": 0.25006359815597534,
      "learning_rate": 1.7752059631227933e-05,
      "loss": 0.1535,
      "step": 3340
    },
    {
      "epoch": 1.9524919848440687,
      "grad_norm": 0.2639475166797638,
      "learning_rate": 1.7653981953707337e-05,
      "loss": 0.152,
      "step": 3350
    },
    {
      "epoch": 1.95832118915768,
      "grad_norm": 0.23268988728523254,
      "learning_rate": 1.755590427618674e-05,
      "loss": 0.1509,
      "step": 3360
    },
    {
      "epoch": 1.9641503934712912,
      "grad_norm": 0.24252837896347046,
      "learning_rate": 1.7457826598666145e-05,
      "loss": 0.1513,
      "step": 3370
    },
    {
      "epoch": 1.9699795977849024,
      "grad_norm": 0.25166627764701843,
      "learning_rate": 1.735974892114555e-05,
      "loss": 0.1513,
      "step": 3380
    },
    {
      "epoch": 1.9758088020985136,
      "grad_norm": 0.24863745272159576,
      "learning_rate": 1.7261671243624953e-05,
      "loss": 0.152,
      "step": 3390
    },
    {
      "epoch": 1.9816380064121248,
      "grad_norm": 0.24338065087795258,
      "learning_rate": 1.7163593566104354e-05,
      "loss": 0.1504,
      "step": 3400
    },
    {
      "epoch": 1.9816380064121248,
      "eval_loss": 0.08963703364133835,
      "eval_runtime": 92.0933,
      "eval_samples_per_second": 375.869,
      "eval_steps_per_second": 46.985,
      "step": 3400
    },
    {
      "epoch": 1.987467210725736,
      "grad_norm": 0.2644537091255188,
      "learning_rate": 1.7065515888583758e-05,
      "loss": 0.1483,
      "step": 3410
    },
    {
      "epoch": 1.9932964150393473,
      "grad_norm": 0.24622513353824615,
      "learning_rate": 1.6967438211063165e-05,
      "loss": 0.15,
      "step": 3420
    },
    {
      "epoch": 1.9991256193529583,
      "grad_norm": 0.24472714960575104,
      "learning_rate": 1.6869360533542566e-05,
      "loss": 0.147,
      "step": 3430
    },
    {
      "epoch": 2.004663363450889,
      "grad_norm": 0.24771861732006073,
      "learning_rate": 1.677128285602197e-05,
      "loss": 0.1393,
      "step": 3440
    },
    {
      "epoch": 2.0104925677645,
      "grad_norm": 0.2542074918746948,
      "learning_rate": 1.6673205178501374e-05,
      "loss": 0.1462,
      "step": 3450
    },
    {
      "epoch": 2.0163217720781113,
      "grad_norm": 0.2407548576593399,
      "learning_rate": 1.6575127500980778e-05,
      "loss": 0.1477,
      "step": 3460
    },
    {
      "epoch": 2.0221509763917225,
      "grad_norm": 0.24739335477352142,
      "learning_rate": 1.6477049823460182e-05,
      "loss": 0.146,
      "step": 3470
    },
    {
      "epoch": 2.0279801807053337,
      "grad_norm": 0.23421867191791534,
      "learning_rate": 1.6378972145939586e-05,
      "loss": 0.1459,
      "step": 3480
    },
    {
      "epoch": 2.033809385018945,
      "grad_norm": 0.2459162026643753,
      "learning_rate": 1.628089446841899e-05,
      "loss": 0.1443,
      "step": 3490
    },
    {
      "epoch": 2.039638589332556,
      "grad_norm": 0.23450420796871185,
      "learning_rate": 1.618281679089839e-05,
      "loss": 0.1461,
      "step": 3500
    },
    {
      "epoch": 2.039638589332556,
      "eval_loss": 0.08910804986953735,
      "eval_runtime": 92.5197,
      "eval_samples_per_second": 374.136,
      "eval_steps_per_second": 46.768,
      "step": 3500
    },
    {
      "epoch": 2.0454677936461674,
      "grad_norm": 0.24754519760608673,
      "learning_rate": 1.6084739113377795e-05,
      "loss": 0.1472,
      "step": 3510
    },
    {
      "epoch": 2.0512969979597786,
      "grad_norm": 0.24672628939151764,
      "learning_rate": 1.59866614358572e-05,
      "loss": 0.1446,
      "step": 3520
    },
    {
      "epoch": 2.05712620227339,
      "grad_norm": 0.23492489755153656,
      "learning_rate": 1.5888583758336603e-05,
      "loss": 0.1449,
      "step": 3530
    },
    {
      "epoch": 2.062955406587001,
      "grad_norm": 0.24384762346744537,
      "learning_rate": 1.5790506080816007e-05,
      "loss": 0.1457,
      "step": 3540
    },
    {
      "epoch": 2.0687846109006123,
      "grad_norm": 0.24972611665725708,
      "learning_rate": 1.569242840329541e-05,
      "loss": 0.1444,
      "step": 3550
    },
    {
      "epoch": 2.074613815214223,
      "grad_norm": 0.23722265660762787,
      "learning_rate": 1.5594350725774815e-05,
      "loss": 0.1427,
      "step": 3560
    },
    {
      "epoch": 2.0804430195278343,
      "grad_norm": 0.2376442551612854,
      "learning_rate": 1.549627304825422e-05,
      "loss": 0.1441,
      "step": 3570
    },
    {
      "epoch": 2.0862722238414455,
      "grad_norm": 0.24310800433158875,
      "learning_rate": 1.5398195370733623e-05,
      "loss": 0.1489,
      "step": 3580
    },
    {
      "epoch": 2.0921014281550567,
      "grad_norm": 0.2523218095302582,
      "learning_rate": 1.5300117693213027e-05,
      "loss": 0.146,
      "step": 3590
    },
    {
      "epoch": 2.097930632468668,
      "grad_norm": 0.2414861023426056,
      "learning_rate": 1.520204001569243e-05,
      "loss": 0.1464,
      "step": 3600
    },
    {
      "epoch": 2.097930632468668,
      "eval_loss": 0.08808717131614685,
      "eval_runtime": 92.5351,
      "eval_samples_per_second": 374.074,
      "eval_steps_per_second": 46.761,
      "step": 3600
    },
    {
      "epoch": 2.103759836782279,
      "grad_norm": 0.235637366771698,
      "learning_rate": 1.5103962338171832e-05,
      "loss": 0.1442,
      "step": 3610
    },
    {
      "epoch": 2.1095890410958904,
      "grad_norm": 0.23949772119522095,
      "learning_rate": 1.5005884660651237e-05,
      "loss": 0.1448,
      "step": 3620
    },
    {
      "epoch": 2.1154182454095016,
      "grad_norm": 0.24503956735134125,
      "learning_rate": 1.490780698313064e-05,
      "loss": 0.1437,
      "step": 3630
    },
    {
      "epoch": 2.121247449723113,
      "grad_norm": 0.24417026340961456,
      "learning_rate": 1.4809729305610042e-05,
      "loss": 0.1457,
      "step": 3640
    },
    {
      "epoch": 2.127076654036724,
      "grad_norm": 0.23999914526939392,
      "learning_rate": 1.4711651628089448e-05,
      "loss": 0.144,
      "step": 3650
    },
    {
      "epoch": 2.1329058583503353,
      "grad_norm": 0.2573221027851105,
      "learning_rate": 1.4613573950568852e-05,
      "loss": 0.145,
      "step": 3660
    },
    {
      "epoch": 2.1387350626639465,
      "grad_norm": 0.22691266238689423,
      "learning_rate": 1.4515496273048254e-05,
      "loss": 0.1422,
      "step": 3670
    },
    {
      "epoch": 2.1445642669775578,
      "grad_norm": 0.24434174597263336,
      "learning_rate": 1.441741859552766e-05,
      "loss": 0.1406,
      "step": 3680
    },
    {
      "epoch": 2.150393471291169,
      "grad_norm": 0.23740524053573608,
      "learning_rate": 1.4319340918007062e-05,
      "loss": 0.143,
      "step": 3690
    },
    {
      "epoch": 2.1562226756047798,
      "grad_norm": 0.23823332786560059,
      "learning_rate": 1.4221263240486465e-05,
      "loss": 0.1423,
      "step": 3700
    },
    {
      "epoch": 2.1562226756047798,
      "eval_loss": 0.08708318322896957,
      "eval_runtime": 94.3421,
      "eval_samples_per_second": 366.909,
      "eval_steps_per_second": 45.865,
      "step": 3700
    },
    {
      "epoch": 2.162051879918391,
      "grad_norm": 0.2424229234457016,
      "learning_rate": 1.412318556296587e-05,
      "loss": 0.1404,
      "step": 3710
    },
    {
      "epoch": 2.167881084232002,
      "grad_norm": 0.22365489602088928,
      "learning_rate": 1.4025107885445275e-05,
      "loss": 0.1412,
      "step": 3720
    },
    {
      "epoch": 2.1737102885456134,
      "grad_norm": 0.25144681334495544,
      "learning_rate": 1.3927030207924677e-05,
      "loss": 0.1417,
      "step": 3730
    },
    {
      "epoch": 2.1795394928592247,
      "grad_norm": 0.23370835185050964,
      "learning_rate": 1.382895253040408e-05,
      "loss": 0.1427,
      "step": 3740
    },
    {
      "epoch": 2.185368697172836,
      "grad_norm": 0.23021122813224792,
      "learning_rate": 1.3730874852883485e-05,
      "loss": 0.1398,
      "step": 3750
    },
    {
      "epoch": 2.191197901486447,
      "grad_norm": 0.24800348281860352,
      "learning_rate": 1.3632797175362887e-05,
      "loss": 0.1417,
      "step": 3760
    },
    {
      "epoch": 2.1970271058000583,
      "grad_norm": 0.24010562896728516,
      "learning_rate": 1.3534719497842291e-05,
      "loss": 0.1434,
      "step": 3770
    },
    {
      "epoch": 2.2028563101136696,
      "grad_norm": 0.24204157292842865,
      "learning_rate": 1.3436641820321697e-05,
      "loss": 0.1406,
      "step": 3780
    },
    {
      "epoch": 2.208685514427281,
      "grad_norm": 0.2599349915981293,
      "learning_rate": 1.33385641428011e-05,
      "loss": 0.1439,
      "step": 3790
    },
    {
      "epoch": 2.214514718740892,
      "grad_norm": 0.23510582745075226,
      "learning_rate": 1.3240486465280502e-05,
      "loss": 0.1423,
      "step": 3800
    },
    {
      "epoch": 2.214514718740892,
      "eval_loss": 0.08640416711568832,
      "eval_runtime": 90.5383,
      "eval_samples_per_second": 382.324,
      "eval_steps_per_second": 47.792,
      "step": 3800
    },
    {
      "epoch": 2.2203439230545032,
      "grad_norm": 0.2597561776638031,
      "learning_rate": 1.3142408787759908e-05,
      "loss": 0.1409,
      "step": 3810
    },
    {
      "epoch": 2.2261731273681145,
      "grad_norm": 0.2320704311132431,
      "learning_rate": 1.304433111023931e-05,
      "loss": 0.1427,
      "step": 3820
    },
    {
      "epoch": 2.2320023316817252,
      "grad_norm": 0.24677881598472595,
      "learning_rate": 1.2946253432718714e-05,
      "loss": 0.1439,
      "step": 3830
    },
    {
      "epoch": 2.2378315359953365,
      "grad_norm": 0.2369217723608017,
      "learning_rate": 1.2848175755198116e-05,
      "loss": 0.1394,
      "step": 3840
    },
    {
      "epoch": 2.2436607403089477,
      "grad_norm": 0.23833554983139038,
      "learning_rate": 1.2750098077677522e-05,
      "loss": 0.1402,
      "step": 3850
    },
    {
      "epoch": 2.249489944622559,
      "grad_norm": 0.2496095448732376,
      "learning_rate": 1.2652020400156924e-05,
      "loss": 0.1416,
      "step": 3860
    },
    {
      "epoch": 2.25531914893617,
      "grad_norm": 0.2313794642686844,
      "learning_rate": 1.2553942722636328e-05,
      "loss": 0.1411,
      "step": 3870
    },
    {
      "epoch": 2.2611483532497814,
      "grad_norm": 0.242369145154953,
      "learning_rate": 1.2455865045115732e-05,
      "loss": 0.1418,
      "step": 3880
    },
    {
      "epoch": 2.2669775575633926,
      "grad_norm": 0.24167205393314362,
      "learning_rate": 1.2357787367595136e-05,
      "loss": 0.142,
      "step": 3890
    },
    {
      "epoch": 2.272806761877004,
      "grad_norm": 0.23860077559947968,
      "learning_rate": 1.2259709690074539e-05,
      "loss": 0.1428,
      "step": 3900
    },
    {
      "epoch": 2.272806761877004,
      "eval_loss": 0.08554016053676605,
      "eval_runtime": 93.1383,
      "eval_samples_per_second": 371.652,
      "eval_steps_per_second": 46.458,
      "step": 3900
    },
    {
      "epoch": 2.278635966190615,
      "grad_norm": 0.23379826545715332,
      "learning_rate": 1.2161632012553943e-05,
      "loss": 0.1393,
      "step": 3910
    },
    {
      "epoch": 2.2844651705042263,
      "grad_norm": 0.2405567616224289,
      "learning_rate": 1.2063554335033347e-05,
      "loss": 0.141,
      "step": 3920
    },
    {
      "epoch": 2.2902943748178375,
      "grad_norm": 0.29597193002700806,
      "learning_rate": 1.1965476657512751e-05,
      "loss": 0.1405,
      "step": 3930
    },
    {
      "epoch": 2.2961235791314487,
      "grad_norm": 0.23741096258163452,
      "learning_rate": 1.1867398979992155e-05,
      "loss": 0.1397,
      "step": 3940
    },
    {
      "epoch": 2.30195278344506,
      "grad_norm": 0.25576865673065186,
      "learning_rate": 1.1769321302471559e-05,
      "loss": 0.1409,
      "step": 3950
    },
    {
      "epoch": 2.3077819877586707,
      "grad_norm": 0.24341091513633728,
      "learning_rate": 1.1671243624950961e-05,
      "loss": 0.1418,
      "step": 3960
    },
    {
      "epoch": 2.313611192072282,
      "grad_norm": 0.2373376339673996,
      "learning_rate": 1.1573165947430365e-05,
      "loss": 0.1391,
      "step": 3970
    },
    {
      "epoch": 2.319440396385893,
      "grad_norm": 0.23789404332637787,
      "learning_rate": 1.147508826990977e-05,
      "loss": 0.1387,
      "step": 3980
    },
    {
      "epoch": 2.3252696006995044,
      "grad_norm": 0.23574523627758026,
      "learning_rate": 1.1377010592389173e-05,
      "loss": 0.1402,
      "step": 3990
    },
    {
      "epoch": 2.3310988050131156,
      "grad_norm": 0.23195438086986542,
      "learning_rate": 1.1278932914868578e-05,
      "loss": 0.1405,
      "step": 4000
    },
    {
      "epoch": 2.3310988050131156,
      "eval_loss": 0.0850146934390068,
      "eval_runtime": 94.0045,
      "eval_samples_per_second": 368.227,
      "eval_steps_per_second": 46.03,
      "step": 4000
    },
    {
      "epoch": 2.336928009326727,
      "grad_norm": 0.2464066445827484,
      "learning_rate": 1.118085523734798e-05,
      "loss": 0.1411,
      "step": 4010
    },
    {
      "epoch": 2.342757213640338,
      "grad_norm": 0.22390349209308624,
      "learning_rate": 1.1082777559827384e-05,
      "loss": 0.1411,
      "step": 4020
    },
    {
      "epoch": 2.3485864179539493,
      "grad_norm": 0.23888912796974182,
      "learning_rate": 1.0984699882306786e-05,
      "loss": 0.1398,
      "step": 4030
    },
    {
      "epoch": 2.3544156222675605,
      "grad_norm": 0.22301046550273895,
      "learning_rate": 1.0886622204786192e-05,
      "loss": 0.1388,
      "step": 4040
    },
    {
      "epoch": 2.3602448265811717,
      "grad_norm": 0.22946497797966003,
      "learning_rate": 1.0788544527265596e-05,
      "loss": 0.1396,
      "step": 4050
    },
    {
      "epoch": 2.366074030894783,
      "grad_norm": 0.23748989403247833,
      "learning_rate": 1.0690466849744998e-05,
      "loss": 0.1386,
      "step": 4060
    },
    {
      "epoch": 2.371903235208394,
      "grad_norm": 0.2256390005350113,
      "learning_rate": 1.0592389172224402e-05,
      "loss": 0.1391,
      "step": 4070
    },
    {
      "epoch": 2.3777324395220054,
      "grad_norm": 0.24501977860927582,
      "learning_rate": 1.0494311494703805e-05,
      "loss": 0.1366,
      "step": 4080
    },
    {
      "epoch": 2.383561643835616,
      "grad_norm": 0.2423313558101654,
      "learning_rate": 1.0396233817183209e-05,
      "loss": 0.1379,
      "step": 4090
    },
    {
      "epoch": 2.389390848149228,
      "grad_norm": 0.23839470744132996,
      "learning_rate": 1.0298156139662615e-05,
      "loss": 0.1393,
      "step": 4100
    },
    {
      "epoch": 2.389390848149228,
      "eval_loss": 0.08412577956914902,
      "eval_runtime": 93.5963,
      "eval_samples_per_second": 369.833,
      "eval_steps_per_second": 46.23,
      "step": 4100
    },
    {
      "epoch": 2.3952200524628386,
      "grad_norm": 0.23003536462783813,
      "learning_rate": 1.0200078462142017e-05,
      "loss": 0.1375,
      "step": 4110
    },
    {
      "epoch": 2.40104925677645,
      "grad_norm": 0.25311341881752014,
      "learning_rate": 1.0102000784621421e-05,
      "loss": 0.1388,
      "step": 4120
    },
    {
      "epoch": 2.406878461090061,
      "grad_norm": 0.22832541167736053,
      "learning_rate": 1.0003923107100823e-05,
      "loss": 0.1384,
      "step": 4130
    },
    {
      "epoch": 2.4127076654036723,
      "grad_norm": 0.23833361268043518,
      "learning_rate": 9.905845429580227e-06,
      "loss": 0.1335,
      "step": 4140
    },
    {
      "epoch": 2.4185368697172835,
      "grad_norm": 0.22982558608055115,
      "learning_rate": 9.807767752059633e-06,
      "loss": 0.1382,
      "step": 4150
    },
    {
      "epoch": 2.4243660740308948,
      "grad_norm": 0.23483674228191376,
      "learning_rate": 9.709690074539035e-06,
      "loss": 0.1402,
      "step": 4160
    },
    {
      "epoch": 2.430195278344506,
      "grad_norm": 0.2510651648044586,
      "learning_rate": 9.61161239701844e-06,
      "loss": 0.1406,
      "step": 4170
    },
    {
      "epoch": 2.436024482658117,
      "grad_norm": 0.24723410606384277,
      "learning_rate": 9.513534719497842e-06,
      "loss": 0.139,
      "step": 4180
    },
    {
      "epoch": 2.4418536869717284,
      "grad_norm": 0.23702502250671387,
      "learning_rate": 9.415457041977246e-06,
      "loss": 0.1357,
      "step": 4190
    },
    {
      "epoch": 2.4476828912853397,
      "grad_norm": 0.2530982494354248,
      "learning_rate": 9.31737936445665e-06,
      "loss": 0.1388,
      "step": 4200
    },
    {
      "epoch": 2.4476828912853397,
      "eval_loss": 0.08339601010084152,
      "eval_runtime": 93.6718,
      "eval_samples_per_second": 369.535,
      "eval_steps_per_second": 46.193,
      "step": 4200
    },
    {
      "epoch": 2.453512095598951,
      "grad_norm": 0.2353885918855667,
      "learning_rate": 9.219301686936054e-06,
      "loss": 0.139,
      "step": 4210
    },
    {
      "epoch": 2.459341299912562,
      "grad_norm": 0.22527529299259186,
      "learning_rate": 9.121224009415458e-06,
      "loss": 0.1378,
      "step": 4220
    },
    {
      "epoch": 2.4651705042261733,
      "grad_norm": 0.23409278690814972,
      "learning_rate": 9.02314633189486e-06,
      "loss": 0.1363,
      "step": 4230
    },
    {
      "epoch": 2.470999708539784,
      "grad_norm": 0.24464137852191925,
      "learning_rate": 8.925068654374264e-06,
      "loss": 0.1386,
      "step": 4240
    },
    {
      "epoch": 2.4768289128533953,
      "grad_norm": 0.23187021911144257,
      "learning_rate": 8.826990976853668e-06,
      "loss": 0.1372,
      "step": 4250
    },
    {
      "epoch": 2.4826581171670066,
      "grad_norm": 0.2507294714450836,
      "learning_rate": 8.728913299333072e-06,
      "loss": 0.1385,
      "step": 4260
    },
    {
      "epoch": 2.488487321480618,
      "grad_norm": 0.23875175416469574,
      "learning_rate": 8.630835621812476e-06,
      "loss": 0.1397,
      "step": 4270
    },
    {
      "epoch": 2.494316525794229,
      "grad_norm": 0.22710712254047394,
      "learning_rate": 8.532757944291879e-06,
      "loss": 0.1372,
      "step": 4280
    },
    {
      "epoch": 2.5001457301078402,
      "grad_norm": 0.23118020594120026,
      "learning_rate": 8.434680266771283e-06,
      "loss": 0.1382,
      "step": 4290
    },
    {
      "epoch": 2.5059749344214515,
      "grad_norm": 0.23459522426128387,
      "learning_rate": 8.336602589250687e-06,
      "loss": 0.137,
      "step": 4300
    },
    {
      "epoch": 2.5059749344214515,
      "eval_loss": 0.08284195512533188,
      "eval_runtime": 90.9301,
      "eval_samples_per_second": 380.677,
      "eval_steps_per_second": 47.586,
      "step": 4300
    },
    {
      "epoch": 2.5118041387350627,
      "grad_norm": 0.23196455836296082,
      "learning_rate": 8.238524911730091e-06,
      "loss": 0.1405,
      "step": 4310
    },
    {
      "epoch": 2.517633343048674,
      "grad_norm": 0.24079731106758118,
      "learning_rate": 8.140447234209495e-06,
      "loss": 0.1377,
      "step": 4320
    },
    {
      "epoch": 2.523462547362285,
      "grad_norm": 0.23244072496891022,
      "learning_rate": 8.042369556688897e-06,
      "loss": 0.1375,
      "step": 4330
    },
    {
      "epoch": 2.5292917516758964,
      "grad_norm": 0.23291730880737305,
      "learning_rate": 7.944291879168301e-06,
      "loss": 0.1378,
      "step": 4340
    },
    {
      "epoch": 2.5351209559895076,
      "grad_norm": 0.23601244390010834,
      "learning_rate": 7.846214201647705e-06,
      "loss": 0.1368,
      "step": 4350
    },
    {
      "epoch": 2.540950160303119,
      "grad_norm": 0.23455531895160675,
      "learning_rate": 7.74813652412711e-06,
      "loss": 0.136,
      "step": 4360
    },
    {
      "epoch": 2.5467793646167296,
      "grad_norm": 0.23784956336021423,
      "learning_rate": 7.650058846606514e-06,
      "loss": 0.1377,
      "step": 4370
    },
    {
      "epoch": 2.5526085689303413,
      "grad_norm": 0.23304545879364014,
      "learning_rate": 7.551981169085916e-06,
      "loss": 0.1351,
      "step": 4380
    },
    {
      "epoch": 2.558437773243952,
      "grad_norm": 0.2594994902610779,
      "learning_rate": 7.45390349156532e-06,
      "loss": 0.1363,
      "step": 4390
    },
    {
      "epoch": 2.5642669775575633,
      "grad_norm": 0.22801773250102997,
      "learning_rate": 7.355825814044724e-06,
      "loss": 0.1367,
      "step": 4400
    },
    {
      "epoch": 2.5642669775575633,
      "eval_loss": 0.08246192336082458,
      "eval_runtime": 93.3489,
      "eval_samples_per_second": 370.813,
      "eval_steps_per_second": 46.353,
      "step": 4400
    },
    {
      "epoch": 2.5700961818711745,
      "grad_norm": 0.23120516538619995,
      "learning_rate": 7.257748136524127e-06,
      "loss": 0.1379,
      "step": 4410
    },
    {
      "epoch": 2.5759253861847857,
      "grad_norm": 0.24492672085762024,
      "learning_rate": 7.159670459003531e-06,
      "loss": 0.135,
      "step": 4420
    },
    {
      "epoch": 2.581754590498397,
      "grad_norm": 0.24539057910442352,
      "learning_rate": 7.061592781482935e-06,
      "loss": 0.1378,
      "step": 4430
    },
    {
      "epoch": 2.587583794812008,
      "grad_norm": 0.233027383685112,
      "learning_rate": 6.9635151039623384e-06,
      "loss": 0.1372,
      "step": 4440
    },
    {
      "epoch": 2.5934129991256194,
      "grad_norm": 0.2450840175151825,
      "learning_rate": 6.8654374264417425e-06,
      "loss": 0.1372,
      "step": 4450
    },
    {
      "epoch": 2.5992422034392306,
      "grad_norm": 0.24174140393733978,
      "learning_rate": 6.767359748921146e-06,
      "loss": 0.1344,
      "step": 4460
    },
    {
      "epoch": 2.605071407752842,
      "grad_norm": 0.2338556945323944,
      "learning_rate": 6.66928207140055e-06,
      "loss": 0.1372,
      "step": 4470
    },
    {
      "epoch": 2.610900612066453,
      "grad_norm": 0.2306656390428543,
      "learning_rate": 6.571204393879954e-06,
      "loss": 0.1369,
      "step": 4480
    },
    {
      "epoch": 2.6167298163800643,
      "grad_norm": 0.2321789562702179,
      "learning_rate": 6.473126716359357e-06,
      "loss": 0.1379,
      "step": 4490
    },
    {
      "epoch": 2.622559020693675,
      "grad_norm": 0.22493302822113037,
      "learning_rate": 6.375049038838761e-06,
      "loss": 0.1345,
      "step": 4500
    },
    {
      "epoch": 2.622559020693675,
      "eval_loss": 0.0819866731762886,
      "eval_runtime": 93.7139,
      "eval_samples_per_second": 369.369,
      "eval_steps_per_second": 46.172,
      "step": 4500
    },
    {
      "epoch": 2.6283882250072867,
      "grad_norm": 0.22476321458816528,
      "learning_rate": 6.276971361318164e-06,
      "loss": 0.1333,
      "step": 4510
    },
    {
      "epoch": 2.6342174293208975,
      "grad_norm": 0.23139940202236176,
      "learning_rate": 6.178893683797568e-06,
      "loss": 0.1377,
      "step": 4520
    },
    {
      "epoch": 2.6400466336345088,
      "grad_norm": 0.23840466141700745,
      "learning_rate": 6.0808160062769714e-06,
      "loss": 0.1382,
      "step": 4530
    },
    {
      "epoch": 2.64587583794812,
      "grad_norm": 0.23421712219715118,
      "learning_rate": 5.9827383287563755e-06,
      "loss": 0.138,
      "step": 4540
    },
    {
      "epoch": 2.651705042261731,
      "grad_norm": 0.2313941866159439,
      "learning_rate": 5.8846606512357795e-06,
      "loss": 0.1338,
      "step": 4550
    },
    {
      "epoch": 2.6575342465753424,
      "grad_norm": 0.2460804134607315,
      "learning_rate": 5.786582973715183e-06,
      "loss": 0.1397,
      "step": 4560
    },
    {
      "epoch": 2.6633634508889537,
      "grad_norm": 0.242081880569458,
      "learning_rate": 5.688505296194587e-06,
      "loss": 0.1365,
      "step": 4570
    },
    {
      "epoch": 2.669192655202565,
      "grad_norm": 0.2241113930940628,
      "learning_rate": 5.59042761867399e-06,
      "loss": 0.1354,
      "step": 4580
    },
    {
      "epoch": 2.675021859516176,
      "grad_norm": 0.2341499924659729,
      "learning_rate": 5.492349941153393e-06,
      "loss": 0.1337,
      "step": 4590
    },
    {
      "epoch": 2.6808510638297873,
      "grad_norm": 0.23090869188308716,
      "learning_rate": 5.394272263632798e-06,
      "loss": 0.1317,
      "step": 4600
    },
    {
      "epoch": 2.6808510638297873,
      "eval_loss": 0.08160524070262909,
      "eval_runtime": 94.5432,
      "eval_samples_per_second": 366.129,
      "eval_steps_per_second": 45.767,
      "step": 4600
    },
    {
      "epoch": 2.6866802681433986,
      "grad_norm": 0.22739948332309723,
      "learning_rate": 5.296194586112201e-06,
      "loss": 0.1375,
      "step": 4610
    },
    {
      "epoch": 2.69250947245701,
      "grad_norm": 0.2391461879014969,
      "learning_rate": 5.198116908591604e-06,
      "loss": 0.1346,
      "step": 4620
    },
    {
      "epoch": 2.6983386767706206,
      "grad_norm": 0.23008371889591217,
      "learning_rate": 5.1000392310710085e-06,
      "loss": 0.136,
      "step": 4630
    },
    {
      "epoch": 2.7041678810842322,
      "grad_norm": 0.2278410941362381,
      "learning_rate": 5.001961553550412e-06,
      "loss": 0.1337,
      "step": 4640
    },
    {
      "epoch": 2.709997085397843,
      "grad_norm": 0.23219861090183258,
      "learning_rate": 4.9038838760298165e-06,
      "loss": 0.1361,
      "step": 4650
    },
    {
      "epoch": 2.7158262897114542,
      "grad_norm": 0.23750920593738556,
      "learning_rate": 4.80580619850922e-06,
      "loss": 0.1362,
      "step": 4660
    },
    {
      "epoch": 2.7216554940250655,
      "grad_norm": 0.219048872590065,
      "learning_rate": 4.707728520988623e-06,
      "loss": 0.137,
      "step": 4670
    },
    {
      "epoch": 2.7274846983386767,
      "grad_norm": 0.2275562733411789,
      "learning_rate": 4.609650843468027e-06,
      "loss": 0.1358,
      "step": 4680
    },
    {
      "epoch": 2.733313902652288,
      "grad_norm": 0.2537115514278412,
      "learning_rate": 4.51157316594743e-06,
      "loss": 0.1366,
      "step": 4690
    },
    {
      "epoch": 2.739143106965899,
      "grad_norm": 0.2360534369945526,
      "learning_rate": 4.413495488426834e-06,
      "loss": 0.1353,
      "step": 4700
    },
    {
      "epoch": 2.739143106965899,
      "eval_loss": 0.08131418377161026,
      "eval_runtime": 93.661,
      "eval_samples_per_second": 369.578,
      "eval_steps_per_second": 46.199,
      "step": 4700
    },
    {
      "epoch": 2.7449723112795104,
      "grad_norm": 0.24956271052360535,
      "learning_rate": 4.315417810906238e-06,
      "loss": 0.1361,
      "step": 4710
    },
    {
      "epoch": 2.7508015155931216,
      "grad_norm": 0.23605631291866302,
      "learning_rate": 4.2173401333856414e-06,
      "loss": 0.134,
      "step": 4720
    },
    {
      "epoch": 2.756630719906733,
      "grad_norm": 0.22616933286190033,
      "learning_rate": 4.1192624558650455e-06,
      "loss": 0.134,
      "step": 4730
    },
    {
      "epoch": 2.762459924220344,
      "grad_norm": 0.23954972624778748,
      "learning_rate": 4.021184778344449e-06,
      "loss": 0.1363,
      "step": 4740
    },
    {
      "epoch": 2.7682891285339553,
      "grad_norm": 0.21982981264591217,
      "learning_rate": 3.923107100823853e-06,
      "loss": 0.1329,
      "step": 4750
    },
    {
      "epoch": 2.774118332847566,
      "grad_norm": 0.2357354462146759,
      "learning_rate": 3.825029423303257e-06,
      "loss": 0.1345,
      "step": 4760
    },
    {
      "epoch": 2.7799475371611777,
      "grad_norm": 0.2276216745376587,
      "learning_rate": 3.72695174578266e-06,
      "loss": 0.1376,
      "step": 4770
    },
    {
      "epoch": 2.7857767414747885,
      "grad_norm": 0.23142211139202118,
      "learning_rate": 3.6288740682620636e-06,
      "loss": 0.1352,
      "step": 4780
    },
    {
      "epoch": 2.7916059457884,
      "grad_norm": 0.22911368310451508,
      "learning_rate": 3.5307963907414676e-06,
      "loss": 0.1349,
      "step": 4790
    },
    {
      "epoch": 2.797435150102011,
      "grad_norm": 0.22400684654712677,
      "learning_rate": 3.4327187132208712e-06,
      "loss": 0.1363,
      "step": 4800
    },
    {
      "epoch": 2.797435150102011,
      "eval_loss": 0.0809953361749649,
      "eval_runtime": 91.809,
      "eval_samples_per_second": 377.033,
      "eval_steps_per_second": 47.13,
      "step": 4800
    },
    {
      "epoch": 2.803264354415622,
      "grad_norm": 0.2370949685573578,
      "learning_rate": 3.334641035700275e-06,
      "loss": 0.135,
      "step": 4810
    },
    {
      "epoch": 2.8090935587292334,
      "grad_norm": 0.23872575163841248,
      "learning_rate": 3.2365633581796785e-06,
      "loss": 0.1375,
      "step": 4820
    },
    {
      "epoch": 2.8149227630428446,
      "grad_norm": 0.2466687560081482,
      "learning_rate": 3.138485680659082e-06,
      "loss": 0.1377,
      "step": 4830
    },
    {
      "epoch": 2.820751967356456,
      "grad_norm": 0.23087617754936218,
      "learning_rate": 3.0404080031384857e-06,
      "loss": 0.1349,
      "step": 4840
    },
    {
      "epoch": 2.826581171670067,
      "grad_norm": 0.21358393132686615,
      "learning_rate": 2.9423303256178898e-06,
      "loss": 0.1357,
      "step": 4850
    },
    {
      "epoch": 2.8324103759836783,
      "grad_norm": 0.22915469110012054,
      "learning_rate": 2.8442526480972934e-06,
      "loss": 0.1356,
      "step": 4860
    },
    {
      "epoch": 2.8382395802972895,
      "grad_norm": 0.22383522987365723,
      "learning_rate": 2.7461749705766966e-06,
      "loss": 0.1371,
      "step": 4870
    },
    {
      "epoch": 2.8440687846109007,
      "grad_norm": 0.22665172815322876,
      "learning_rate": 2.6480972930561006e-06,
      "loss": 0.1356,
      "step": 4880
    },
    {
      "epoch": 2.849897988924512,
      "grad_norm": 0.23154912889003754,
      "learning_rate": 2.5500196155355042e-06,
      "loss": 0.1345,
      "step": 4890
    },
    {
      "epoch": 2.855727193238123,
      "grad_norm": 0.23066863417625427,
      "learning_rate": 2.4519419380149083e-06,
      "loss": 0.1364,
      "step": 4900
    },
    {
      "epoch": 2.855727193238123,
      "eval_loss": 0.08078260719776154,
      "eval_runtime": 93.2357,
      "eval_samples_per_second": 371.264,
      "eval_steps_per_second": 46.409,
      "step": 4900
    },
    {
      "epoch": 2.861556397551734,
      "grad_norm": 0.2239147573709488,
      "learning_rate": 2.3538642604943115e-06,
      "loss": 0.1385,
      "step": 4910
    },
    {
      "epoch": 2.8673856018653456,
      "grad_norm": 0.21757537126541138,
      "learning_rate": 2.255786582973715e-06,
      "loss": 0.1351,
      "step": 4920
    },
    {
      "epoch": 2.8732148061789564,
      "grad_norm": 0.22403164207935333,
      "learning_rate": 2.157708905453119e-06,
      "loss": 0.1325,
      "step": 4930
    },
    {
      "epoch": 2.8790440104925676,
      "grad_norm": 0.22165583074092865,
      "learning_rate": 2.0596312279325227e-06,
      "loss": 0.1344,
      "step": 4940
    },
    {
      "epoch": 2.884873214806179,
      "grad_norm": 0.22834928333759308,
      "learning_rate": 1.9615535504119264e-06,
      "loss": 0.1366,
      "step": 4950
    },
    {
      "epoch": 2.89070241911979,
      "grad_norm": 0.24122263491153717,
      "learning_rate": 1.86347587289133e-06,
      "loss": 0.1352,
      "step": 4960
    },
    {
      "epoch": 2.8965316234334013,
      "grad_norm": 0.23116683959960938,
      "learning_rate": 1.7653981953707338e-06,
      "loss": 0.1348,
      "step": 4970
    },
    {
      "epoch": 2.9023608277470125,
      "grad_norm": 0.24699436128139496,
      "learning_rate": 1.6673205178501374e-06,
      "loss": 0.1363,
      "step": 4980
    },
    {
      "epoch": 2.9081900320606238,
      "grad_norm": 0.23368041217327118,
      "learning_rate": 1.569242840329541e-06,
      "loss": 0.1347,
      "step": 4990
    },
    {
      "epoch": 2.914019236374235,
      "grad_norm": 0.23439304530620575,
      "learning_rate": 1.4711651628089449e-06,
      "loss": 0.1353,
      "step": 5000
    },
    {
      "epoch": 2.914019236374235,
      "eval_loss": 0.0806347131729126,
      "eval_runtime": 94.1833,
      "eval_samples_per_second": 367.528,
      "eval_steps_per_second": 45.942,
      "step": 5000
    },
    {
      "epoch": 2.919848440687846,
      "grad_norm": 0.2304011583328247,
      "learning_rate": 1.3730874852883483e-06,
      "loss": 0.1352,
      "step": 5010
    },
    {
      "epoch": 2.9256776450014574,
      "grad_norm": 0.2288004606962204,
      "learning_rate": 1.2750098077677521e-06,
      "loss": 0.1352,
      "step": 5020
    },
    {
      "epoch": 2.9315068493150687,
      "grad_norm": 0.22124862670898438,
      "learning_rate": 1.1769321302471557e-06,
      "loss": 0.1334,
      "step": 5030
    },
    {
      "epoch": 2.9373360536286794,
      "grad_norm": 0.22874751687049866,
      "learning_rate": 1.0788544527265596e-06,
      "loss": 0.1362,
      "step": 5040
    },
    {
      "epoch": 2.943165257942291,
      "grad_norm": 0.22739554941654205,
      "learning_rate": 9.807767752059632e-07,
      "loss": 0.1358,
      "step": 5050
    },
    {
      "epoch": 2.948994462255902,
      "grad_norm": 0.22368794679641724,
      "learning_rate": 8.826990976853669e-07,
      "loss": 0.1356,
      "step": 5060
    },
    {
      "epoch": 2.954823666569513,
      "grad_norm": 0.2242184281349182,
      "learning_rate": 7.846214201647705e-07,
      "loss": 0.1352,
      "step": 5070
    },
    {
      "epoch": 2.9606528708831243,
      "grad_norm": 0.22668024897575378,
      "learning_rate": 6.865437426441741e-07,
      "loss": 0.1377,
      "step": 5080
    },
    {
      "epoch": 2.9664820751967356,
      "grad_norm": 0.22805404663085938,
      "learning_rate": 5.884660651235779e-07,
      "loss": 0.135,
      "step": 5090
    },
    {
      "epoch": 2.972311279510347,
      "grad_norm": 0.2355363816022873,
      "learning_rate": 4.903883876029816e-07,
      "loss": 0.1371,
      "step": 5100
    },
    {
      "epoch": 2.972311279510347,
      "eval_loss": 0.08057799935340881,
      "eval_runtime": 93.5236,
      "eval_samples_per_second": 370.12,
      "eval_steps_per_second": 46.266,
      "step": 5100
    },
    {
      "epoch": 2.978140483823958,
      "grad_norm": 0.22581610083580017,
      "learning_rate": 3.9231071008238526e-07,
      "loss": 0.1333,
      "step": 5110
    },
    {
      "epoch": 2.9839696881375692,
      "grad_norm": 0.22570781409740448,
      "learning_rate": 2.9423303256178893e-07,
      "loss": 0.1347,
      "step": 5120
    },
    {
      "epoch": 2.9897988924511805,
      "grad_norm": 0.2207207977771759,
      "learning_rate": 1.9615535504119263e-07,
      "loss": 0.1345,
      "step": 5130
    },
    {
      "epoch": 2.9956280967647917,
      "grad_norm": 0.2272411435842514,
      "learning_rate": 9.807767752059632e-08,
      "loss": 0.1333,
      "step": 5140
    }
  ],
  "logging_steps": 10,
  "max_steps": 5148,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.931615767632282e+16,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
